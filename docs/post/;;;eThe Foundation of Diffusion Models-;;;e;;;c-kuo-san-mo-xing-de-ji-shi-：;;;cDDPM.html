<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark_colorblind" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://OmnisyR.github.io/assets/Primer.css' rel='stylesheet' />
    <script src='https://OmnisyR.github.io/assets/GmeekVercount.js'></script><script src='https://OmnisyR.github.io/assets/Language.js'></script><meta name='google-site-verification' content='jL_vSMve-woq2yALbGnRHeP86_xTVwPvJYu6vfAQiWo' />
    <link rel="icon" href="https://avatars.githubusercontent.com/u/68898477?s=400&u=262ae3b76f651c62a82042317aaae313706c859c&v=4"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="<!-- ##{'script':'<script src='https://OmnisyR.github.io/assets/HyperTOC.js'></script>'}## -->
> [!IMPORTANT]
> ;;;eTo read this article, readers should:
> - Be proficient in Python
> - Have a foundation in PyTorch
> - Possess a basic understanding of neural networks;;;e;;;c阅读本文，需要读者：
> - 能够熟练使用Python语言
> - 拥有Pytorch基础
> - 拥有神经网络基础;;;c

;;;a
;;;;;;;eMarkov chain::The state at a given moment is only related to the state at the previous moment, i.e., $x_t = f(x_{t - 1})$, without the involvement of states at other moments. A chain formed by a number of such state relationships constitutes a Markov chain. Therefore, Markov chains have the following special properties:;;;e;;;c马尔可夫链::某一时刻的状态只与上一时刻的状态相关，即$x_t = f(x_{t - 1})$，不需要其他时刻的状态参与，若干个这样的状态关系组成的链条便形成了马尔科夫链。">
<meta property="og:title" content=";;;eThe Foundation of Diffusion Models:;;;e;;;c扩散模型的基石：;;;cDDPM">
<meta property="og:description" content="<!-- ##{'script':'<script src='https://OmnisyR.github.io/assets/HyperTOC.js'></script>'}## -->
> [!IMPORTANT]
> ;;;eTo read this article, readers should:
> - Be proficient in Python
> - Have a foundation in PyTorch
> - Possess a basic understanding of neural networks;;;e;;;c阅读本文，需要读者：
> - 能够熟练使用Python语言
> - 拥有Pytorch基础
> - 拥有神经网络基础;;;c

;;;a
;;;;;;;eMarkov chain::The state at a given moment is only related to the state at the previous moment, i.e., $x_t = f(x_{t - 1})$, without the involvement of states at other moments. A chain formed by a number of such state relationships constitutes a Markov chain. Therefore, Markov chains have the following special properties:;;;e;;;c马尔可夫链::某一时刻的状态只与上一时刻的状态相关，即$x_t = f(x_{t - 1})$，不需要其他时刻的状态参与，若干个这样的状态关系组成的链条便形成了马尔科夫链。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://OmnisyR.github.io/post/%3B%3B%3BeThe%20Foundation%20of%20Diffusion%20Models-%3B%3B%3Be%3B%3B%3Bc-kuo-san-mo-xing-de-ji-shi-%EF%BC%9A%3B%3B%3BcDDPM.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/68898477?s=400&u=262ae3b76f651c62a82042317aaae313706c859c&v=4">
<title>;;;eThe Foundation of Diffusion Models:;;;e;;;c扩散模型的基石：;;;cDDPM</title>
<link href="//unpkg.com/@wooorm/starry-night@2.1.1/style/both.css" rel="stylesheet" />


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>
<style>.markdown-alert{padding:0.5rem 1rem;margin-bottom:1rem;border-left:.25em solid var(--borderColor-default,var(--color-border-default));}.markdown-alert .markdown-alert-title {display:flex;font-weight:var(--base-text-weight-medium,500);align-items:center;line-height:1;}.markdown-alert>:first-child {margin-top:0;}.markdown-alert>:last-child {margin-bottom:0;}</style><style>.markdown-alert.markdown-alert-important {border-left-color:var(--borderColor-done-emphasis, var(--color-done-emphasis));background-color:var(--color-done-subtle);}.markdown-alert.markdown-alert-important .markdown-alert-title {color: var(--fgColor-done,var(--color-done-fg));}</style>



<body>
    <div id="header">
<h1 class="postTitle">;;;eThe Foundation of Diffusion Models:;;;e;;;c扩散模型的基石：;;;cDDPM</h1>
<div class="title-right">
    <a href="https://OmnisyR.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/OmnisyR/OmnisyR.github.io/issues/6" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody">
<div class="markdown-alert markdown-alert-important"><p class="markdown-alert-title"><svg class="octicon octicon-report mr-2" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0 1 14.25 13H8.06l-2.573 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25Zm7 2.25v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 9a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg>Important</p><p>;;;eTo read this article, readers should:</p>
<ul>
<li>Be proficient in Python</li>
<li>Have a foundation in PyTorch</li>
<li>Possess a basic understanding of neural networks;;;e;;;c阅读本文，需要读者：</li>
<li>能够熟练使用Python语言</li>
<li>拥有Pytorch基础</li>
<li>拥有神经网络基础;;;c</li>
</ul>
</div>
<p>;;;a<br>
;;;;;;;eMarkov chain::The state at a given moment is only related to the state at the previous moment, i.e., $x_t = f(x_{t - 1})$, without the involvement of states at other moments. A chain formed by a number of such state relationships constitutes a Markov chain. Therefore, Markov chains have the following special properties:;;;e;;;c马尔可夫链::某一时刻的状态只与上一时刻的状态相关，即$x_t = f(x_{t - 1})$，不需要其他时刻的状态参与，若干个这样的状态关系组成的链条便形成了马尔科夫链。因此，马尔科夫链存在着这样的特殊性质：;;;c</p>
<p>$$
\begin{align}
&amp;P(X_n|X_0) = P(X_n)
\\
&amp;P(X_n|X_{n - 1}, X_{n - 2}, \dots, X_0) = P(X_n|X_{n - 1})
\end{align}
$$</p>
<p>;;;;<br>
;;;;;;;eReparameterization trick::For the probability $p(x|y) = \mathcal{N}(x|ay, b)$, i.e., $x$ follows a Gaussian distribution with mean $ay$ and standard deviation $\sqrt{b}$, then we have $x = ay + \sqrt{b}\epsilon$, where $\epsilon \sim \mathcal{N}(0, 1)$.;;;e;;;c重参数化技巧::对于概率$p(x|y) = \mathcal{N}(x|ay, b)$，即$x$服从一个均值为$ay$，标准差为$\sqrt{b}$的高斯分布，那么则有$x = ay + \sqrt{b}\epsilon$，其中$\epsilon \sim \mathcal{N}(0, 1)$。;;;c;;;;<br>
;;;;;;;eThe code below::PyTorch code that uses GPU acceleration by default. Due to the enormous computing power required by diffusion models, it is almost impossible to run diffusion models without GPU acceleration.;;;e;;;c下方的代码::默认使用GPU加速的pytorch代码，由于扩散模型需求算力巨大，不使用GPU加速几乎很难跑得了扩散模型。;;;c;;;;<br>
;;;;;;;eAddition rule of Gaussian distribution;;;e;;;c高斯分布的加法法则;;;c::</p>
<p>$$
\mathcal{N}(\mu_1, \sigma^2_1) + \mathcal{N}(\mu_2, \sigma^2_2) = \mathcal{N}(\mu_1 + \mu_2, \sigma^2_1 + \sigma^2_2)
$$</p>
<p>;;;;<br>
;;;;;;;eThe upper bound of this loss as small as possible::Some people may have a typical misconception, namely that equation (13) is equivalent to the KL divergence on the right side being 0. This idea is incorrect because when the KL divergence is 0, although the gradient of the KL divergence is 0, the overall gradient on the right side is not necessarily 0. A very simple example can effectively illustrate this point:;;;e;;;c上界尽可能的小::有些人会存在一个典型的认识错误，即认为式(13)等价于目标为右方的KL散度为0。这个想法错在KL散度为0时，虽然KL散度的梯度为0，但右方整体的梯度不一定为0，一个很简单的例子就能有效进行说明：;;;c</p>
<p>$$
x^2 \leq x^2 + (2 - x)^2
$$</p>
<p>;;;eClearly, the right-hand side takes its minimum value at $x = 1$, rather than at $x = 2$, where $(2 - x)^2$ is 0.;;;e;;;c显然，右式在$x = 1$时取最小值，而非令$(2 - x)^2$为0的$x = 2$时。;;;c</p>
<p>;;;;<br>
;;;;;;;eBayes' theorem;;;e;;;c贝叶斯定理;;;c::</p>
<p>$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$</p>
<p>;;;;<br>
;;;;;;;eEquation ;;;e;;;c式;;;c(10)::</p>
<p>$$
x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon_t
$$</p>
<p>;;;;<br>
;;;;;;;eKL divergence formula for Gaussian distributions::For $p_1(x) = \mathcal{N}(\mu_1, \sigma^2_1)$ and $p_2(x) = \mathcal{N}(\mu_2, \sigma^2_2)$, we have:;;;e;;;c高斯分布的KL散度公式::对于$p_1(x) = \mathcal{N}(\mu_1, \sigma^2_1)$以及$p_2(x) = \mathcal{N}(\mu_2, \sigma^2_2)$，有：;;;c</p>
<p>$$
D_{KL}(p_1||p_2) = \frac{1}{2}\log\frac{\sigma^2_2}{\sigma^2_1} + \frac{\sigma^2_1 + (\mu_1 - \mu_2)^2}{2\sigma^2_2} - \frac{1}{2}
$$</p>
<p>;;;;<br>
;;;;UNet::;;;e<a href="https://arxiv.org/abs/1505.04597" rel="nofollow">Article address</a>;;;e;;;c<a href="https://arxiv.org/abs/1505.04597" rel="nofollow">文章地址</a>;;;c<br>
;;;eUNet is relatively complex. You can download <a href="https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/unet.py">unet.py</a> and <a href="https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/nn.py">nn.py</a> provided by the article <a href="https://arxiv.org/abs/2105.05233" rel="nofollow">Diffusion Models Beat GANs on Image Synthesis</a> on GitHub to run the diffusion model. You do not need to download fp16_util.py. Simply delete the relevant code in unet.py before running it.;;;e;;;c;UNet较为复杂，可以在Github上下载由文章<a href="https://arxiv.org/abs/2105.05233" rel="nofollow">Diffusion Models Beat GANs on Image Synthesis</a>提供的<a href="https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/unet.py">unet.py</a>以及<a href="https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/nn.py">nn.py</a>来运行扩散模型，fp16_util.py可以不用下载，运行前将unet.py中相关代码删去即可。;;;c;;;;<br>
;;;;;;;eResidual idea::<a href="https://arxiv.org/abs/1512.03385" rel="nofollow">Article address</a>;;;e;;;c残差思想::<a href="https://arxiv.org/abs/1512.03385" rel="nofollow">文章地址</a>;;;c;;;;<br>
;;;;Attention is All You Need::;;;e<a href="https://arxiv.org/abs/1706.03762" rel="nofollow">Article address</a>;;;e;;;c<a href="https://arxiv.org/abs/1706.03762" rel="nofollow">文章地址</a>;;;c;;;;<br>
;;;;;;;eSelect a linear noise schedule::There are many types of noise schedules. Although cosine noise schedule seem to be highly recommended online, in actual practice, they can cause a problem I call “color divergence.” A series of measures are required to improve the results and obtain the correct outcome. Therefore, when you are just starting to learn about diffusion models, it is best to use a linear noise schedule first.;;;e;;;c选择线性噪声时间表::噪声时间表有很多种，虽然网络上疑似很推崇余弦型噪声时间表，但实际操作中它会导致一种被我称为“色彩发散”的问题，还需要通过一系列手段来改善才能得到正确结果，所以刚刚接触扩散模型，可以先使用线性噪声时间表。;;;c;;;;<br>
;;;;;;;eEquation ;;;e;;;c式;;;c(50)::</p>
<p>$$
\begin{align}
x_{t - 1} &amp;= \frac{1}{\sqrt{\alpha_t}}x_t
\\
&amp;\quad - \frac{1 - \alpha_t}{\sqrt{\alpha_t(1 - \bar{\alpha}_t)}}\epsilon_\theta(x_t, t)
\\
&amp;\quad + \sqrt{\frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t}\epsilon
\end{align}
$$</p>
<p>;;;;<br>
;;;;;;;eThe limitations of the blog framework::The total number of characters in a single article is limited to 65,536.;;;e;;;c博客框架的限制::单篇文章的总字符数被限制在了65,536内。;;;c;;;;<br>
;;;a;;;e</p>
<h2>Introduction</h2>
<p>I'm not very good at describing subjective things, and most of the information about diffusion models has already been covered in <a href="https://omnisyr.github.io/post/%3B%3B%3BeAn%20Overview%20of%20Diffusion%20Models%3B%3B%3Be%3B%3B%3Bc-kuo-san-mo-xing-gai-shu-%3B%3B%3Bc.html" rel="nofollow">Diffusion Model Overview</a>, so I'll skip the formalities and get straight to the point!</p>
<p>In this article, I will introduce and implement DDPM from a mathematical and coding perspective. If you just want to try it out, you can copy and paste the code directly, modify a few path parameters, and run it right away, provided your environment is properly configured!</p>
<h2>Forward Process</h2>
<p>The forward process of the diffusion models involve gradually adding noise to the original image, such that by the final stage, the image fully follows the noise distribution. Typically, Gaussian noise is used for this process. For discrete time points $t = 0, 1, \dots, T$, in the <code class="notranslate">Markov chain</code> process followed by the diffusion models, given $x_0 \sim q(x_0)$, i.e., the original image as the initial stage, and $x_T \sim q(x_T) = \mathcal{N}(0, I)$, i.e., the image completely following standard Gaussian noise as the final stage. The probability distributions of the various stages $x_0, x_1, \dots, x_T$ follow the following formula:;;;e;;;c</p>
<h2>介绍</h2>
<p>我不擅长描述一些非客观性的东西，一些关于扩散模型的介绍在<a href="https://omnisyr.github.io/post/%3B%3B%3BeAn%20Overview%20of%20Diffusion%20Models%3B%3B%3Be%3B%3B%3Bc-kuo-san-mo-xing-gai-shu-%3B%3B%3Bc.html" rel="nofollow">扩散模型概述</a>中也讲的差不多了，所以没有繁文缛节了，直接开始吧！</p>
<p>在这篇文章中，我将从数学和代码上介绍和实现DDPM。如果你只是想单纯实践的话，在环境配置好的条件下，你可以直接复制粘贴，修改几个路径参数便可直接运行！</p>
<h2>正向过程</h2>
<p>扩散模型的正向过程为，对原始的图像进行一步步地噪声添加，从而在最终阶段，使得图片完全服从噪声分布，一般地，使用高斯噪声来进行这个过程。对于离散的时间$t = 0, 1, \dots, T$，在扩散模型遵循的<code class="notranslate">马尔可夫链</code>过程中，对于给定的$x_0 \sim q(x_0)$，即原始图像作为初始阶段，和$x_T \sim q(x_T) = \mathcal{N}(0, I)$，即完全服从标准高斯噪声的图像作为最终阶段。其各个阶段$x_0, x_1, \dots, x_T$的概率分布服从以下公式：;;;c</p>
<p>$$
q(x_T|x_0) = q(x_0)\prod^T_{t = 1}q(x_t|x_{t - 1})
\tag{1}
$$</p>
<p>;;;ewhere $q(x_{t + 1}|x_{t})$ represents the process of adding noise to the image at the previous moment at each moment. Obviously, this process needs to be defined manually, so a set of hyperparameters $\beta_t$ can be selected, resulting in:;;;e;;;c其中$q(x_{t + 1}|x_{t})$代表着每一时刻，为上一时刻的图片添加噪声的过程。很显然，这个过程是需要人为定义的，因此，可以选择一组超参数$\beta_t$，从而有：;;;c</p>
<p>$$
q(x_t|x_{t - 1}) = \mathcal{N}(x_t;\sqrt{1 - \beta_t}x_{t - 1},\beta_tI)
\tag{2}
$$</p>
<p>;;;eHowever, such an equation is still incomputable. Through the <code class="notranslate">Reparameterization trick</code>, any Gaussian distribution can be expanded, so we have:;;;e;;;c但是，这样的式子仍然是不可计算的，通过<code class="notranslate">重参数化技巧</code>，可以将任意的高斯分布进行展开，因此则有：;;;c</p>
<p>$$
x_t = \sqrt{1 - \beta_t} x_{t - 1} + \sqrt{\beta_t}\epsilon
\tag{3}
$$</p>
<p>;;;eIn this way, a computable form is used to express the Markov chain forward process of the diffusion model. In DDPM, $\beta_t$ is defined as a linear array ranging from $\beta_1 = 0.001$ to $\beta_T = 0.02$. This method of adding noise is also known as a linear noise schedule. The process can be implemented using <code class="notranslate">The code below</code>:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">import</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">io</span>
<span class="pl-k">from</span> <span class="pl-c1">PIL</span> <span class="pl-k">import</span> <span class="pl-v">Image</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">transforms</span>.<span class="pl-s1">v2</span> <span class="pl-k">import</span> <span class="pl-v">Compose</span>, <span class="pl-v">ToTensor</span>, <span class="pl-v">Lambda</span>
<span class="pl-k">from</span> <span class="pl-s1">tqdm</span> <span class="pl-k">import</span> <span class="pl-s1">tqdm</span>

<span class="pl-c">#The timesteps is set to the commonly used 1000.</span>
<span class="pl-s1">timesteps</span> <span class="pl-c1">=</span> <span class="pl-c1">1000</span>
<span class="pl-c">#Convert the color values of the image into a tensor between -1 and 1.</span>
<span class="pl-s1">transform</span> <span class="pl-c1">=</span> <span class="pl-en">Compose</span>([<span class="pl-en">ToTensor</span>(), <span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">*</span> <span class="pl-c1">2</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>)])
<span class="pl-c">#Convert images with color values between -1 and 1 to values between 0 and 255.</span>
<span class="pl-s1">transform_reverse</span> <span class="pl-c1">=</span> <span class="pl-en">Compose</span>([<span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>) <span class="pl-c1">/</span> <span class="pl-c1">2</span> <span class="pl-c1">*</span> <span class="pl-c1">255</span>)])
<span class="pl-c">#Read and convert images into tensors.</span>
<span class="pl-s1">x_t</span> <span class="pl-c1">=</span> <span class="pl-en">transform</span>(<span class="pl-v">Image</span>.<span class="pl-c1">open</span>(<span class="pl-s">'xxx.png'</span>)).<span class="pl-c1">cuda</span>()
<span class="pl-c">#Use a linear noise schedule.</span>
<span class="pl-s1">beta</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">linspace</span>(<span class="pl-c1">0.001</span>, <span class="pl-c1">0.02</span>, <span class="pl-s1">timesteps</span>).<span class="pl-c1">cuda</span>()
<span class="pl-k">for</span> <span class="pl-s1">timestep</span> <span class="pl-c1">in</span> <span class="pl-en">tqdm</span>(<span class="pl-en">range</span>(<span class="pl-s1">timesteps</span>)):
    <span class="pl-c">#Random noise at each step.</span>
    <span class="pl-s1">ep</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span><span class="pl-s1">x_t</span>.<span class="pl-c1">shape</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#Iterative noise addition process of equation (3).</span>
    <span class="pl-s1">x_t</span> <span class="pl-c1">=</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">beta</span>[<span class="pl-s1">timestep</span>]).<span class="pl-c1">sqrt</span>().<span class="pl-c1">item</span>() <span class="pl-c1">*</span> <span class="pl-s1">x_t</span> <span class="pl-c1">+</span> <span class="pl-s1">beta</span>[<span class="pl-s1">timestep</span>].<span class="pl-c1">sqrt</span>() <span class="pl-c1">*</span> <span class="pl-s1">ep</span>
    <span class="pl-c">#Save image to local.</span>
    <span class="pl-s1">torchvision</span>.<span class="pl-c1">io</span>.<span class="pl-c1">write_png</span>(
      <span class="pl-en">transform_reverse</span>(<span class="pl-s1">x_t</span>).<span class="pl-c1">clip</span>(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>).<span class="pl-c1">cpu</span>(),
      <span class="pl-s">'noising/%d.png'</span> <span class="pl-c1">%</span> <span class="pl-s1">timestep</span>
    )</pre></div>
<p>;;;e;;;c这样一来，就使用了一个可计算的形式表达出了扩散模型的马尔科夫链正向过程。DDPM中定义$\beta_t$是一个从$\beta_1 = 0.001$到$\beta_T = 0.02$的线性数组，这种噪声添加方式又称线性噪声时间表。通过<code class="notranslate">下方的代码</code>便可以实现这一过程：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">import</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">io</span>
<span class="pl-k">from</span> <span class="pl-c1">PIL</span> <span class="pl-k">import</span> <span class="pl-v">Image</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">transforms</span>.<span class="pl-s1">v2</span> <span class="pl-k">import</span> <span class="pl-v">Compose</span>, <span class="pl-v">ToTensor</span>, <span class="pl-v">Lambda</span>
<span class="pl-k">from</span> <span class="pl-s1">tqdm</span> <span class="pl-k">import</span> <span class="pl-s1">tqdm</span>

<span class="pl-c">#时间长度设置为较为常用的1000</span>
<span class="pl-s1">timesteps</span> <span class="pl-c1">=</span> <span class="pl-c1">1000</span>
<span class="pl-c">#将图片的色彩值转化为-1到1之间的张量</span>
<span class="pl-s1">transform</span> <span class="pl-c1">=</span> <span class="pl-en">Compose</span>([<span class="pl-en">ToTensor</span>(), <span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">*</span> <span class="pl-c1">2</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>)])
<span class="pl-c">#将色彩值为-1到1之间的图片转化为0到255之间</span>
<span class="pl-s1">transform_reverse</span> <span class="pl-c1">=</span> <span class="pl-en">Compose</span>([<span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>) <span class="pl-c1">/</span> <span class="pl-c1">2</span> <span class="pl-c1">*</span> <span class="pl-c1">255</span>)])
<span class="pl-c">#读取并将图片转化为张量</span>
<span class="pl-s1">x_t</span> <span class="pl-c1">=</span> <span class="pl-en">transform</span>(<span class="pl-v">Image</span>.<span class="pl-c1">open</span>(<span class="pl-s">'xxx.png'</span>)).<span class="pl-c1">cuda</span>()
<span class="pl-c">#使用线性噪声时间表</span>
<span class="pl-s1">beta</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">linspace</span>(<span class="pl-c1">0.001</span>, <span class="pl-c1">0.02</span>, <span class="pl-s1">timesteps</span>).<span class="pl-c1">cuda</span>()
<span class="pl-k">for</span> <span class="pl-s1">timestep</span> <span class="pl-c1">in</span> <span class="pl-en">tqdm</span>(<span class="pl-en">range</span>(<span class="pl-s1">timesteps</span>)):
    <span class="pl-c">#每一步的随机噪声</span>
    <span class="pl-s1">ep</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span><span class="pl-s1">x_t</span>.<span class="pl-c1">shape</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#式(3)的迭代增噪过程</span>
    <span class="pl-s1">x_t</span> <span class="pl-c1">=</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">beta</span>[<span class="pl-s1">timestep</span>]).<span class="pl-c1">sqrt</span>().<span class="pl-c1">item</span>() <span class="pl-c1">*</span> <span class="pl-s1">x_t</span> <span class="pl-c1">+</span> <span class="pl-s1">beta</span>[<span class="pl-s1">timestep</span>].<span class="pl-c1">sqrt</span>() <span class="pl-c1">*</span> <span class="pl-s1">ep</span>
    <span class="pl-c">#保存图片到本地</span>
    <span class="pl-s1">torchvision</span>.<span class="pl-c1">io</span>.<span class="pl-c1">write_png</span>(
      <span class="pl-en">transform_reverse</span>(<span class="pl-s1">x_t</span>).<span class="pl-c1">clip</span>(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>).<span class="pl-c1">cpu</span>(),
      <span class="pl-s">'noising/%d.png'</span> <span class="pl-c1">%</span> <span class="pl-s1">timestep</span>
    )</pre></div>
<p>;;;c</p>
<p>;;;eFor simplicity, let $\alpha_t + \beta_t = 1$, then we have:;;;e;;;c为了式子的简洁性，记$\alpha_t + \beta_t = 1$，则有：;;;c</p>
<p>$$
\begin{align}
x_t &amp;= \sqrt{\alpha_t} x_{t - 1} + \sqrt{1 - \alpha_t}\tilde{\epsilon}_t
\tag{4}
\\
&amp;= \sqrt{\alpha_t}(\sqrt{\alpha_{{t - 1}}} x_{t - 2} + \sqrt{1 - \alpha_{t - 1}}\tilde{\epsilon}_{t - 1}) + \sqrt{1 - \alpha_t}\tilde{\epsilon}_t
\tag{5}
\\
&amp;= \sqrt{\alpha_t\alpha_{t - 1}}x_{t - 2} + \sqrt{\alpha_t(1 - \alpha_{t - 1})}\tilde{\epsilon}_{t - 1} + \sqrt{1 - \alpha_t}\tilde{\epsilon}_t
\tag{6}
\\
&amp;= \sqrt{\alpha_t\alpha_{t - 1}}x_{t - 2} + \mathcal{N}(0, \alpha_t(1 - \alpha_{t - 1})) + \mathcal{N}(0, 1 - \alpha_t)
\tag{7}
\\
&amp;= \sqrt{\alpha_t\alpha_{t - 1}}x_{t - 2} + \mathcal{N}(0, \alpha_t(1 - \alpha_{t - 1}) + 1 - \alpha_t)
\tag{8}
\\
&amp;= \sqrt{\alpha_t\alpha_{t - 1}}x_{t - 2} + \sqrt{1 - \alpha_t\alpha_{t - 1}}\bar{\epsilon}_{t, t - 1}
\tag{9}
\\
&amp;= \dots
\\
&amp;= \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon_t
\tag{10}
\end{align}
$$</p>
<p>;;;ewhere $\bar{\alpha}_t = \prod_{i = 1}^{t}\alpha_i$. Since there are two completely random standard Gaussian distributions in equation (6), we can perform the inverse operation of the reparameterization technique on these two to obtain equation (7), and then use the <code class="notranslate">Addition rule of Gaussian distribution</code> to obtain equation (8), thereby simplifying the multi-step iteration and enabling us to calculate the state at any time in the forward process in a single step:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">t</span>):
    <span class="pl-c">#The one-step noise addition process in equation (10).</span>
    <span class="pl-k">return</span> <span class="pl-s1">sqrt_alpha_bar</span>[<span class="pl-s1">t</span>] <span class="pl-c1">*</span> <span class="pl-s1">x_0</span> <span class="pl-c1">+</span> <span class="pl-s1">sqrt_one_minus_alpha_bar</span>[<span class="pl-s1">t</span>] <span class="pl-c1">*</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span><span class="pl-s1">x_0</span>.<span class="pl-c1">shape</span>).<span class="pl-c1">cuda</span>()

<span class="pl-c">#Pre-caching of parameters.</span>
<span class="pl-s1">alpha</span> <span class="pl-c1">=</span> <span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">beta</span>
<span class="pl-c">#Here, an extra 1 is added to the front position of the obtained α product.</span>
<span class="pl-c">#This is to ensure consistency between the timestamp and the index when writing the program.</span>
<span class="pl-s1">alpha_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">cat</span>((<span class="pl-s1">torch</span>.<span class="pl-c1">Tensor</span>((<span class="pl-c1">1</span>,)).<span class="pl-c1">cuda</span>(), <span class="pl-s1">alpha</span>.<span class="pl-c1">cumprod</span>(<span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">0</span>)))
<span class="pl-s1">sqrt_alpha_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">alpha_bar</span>.<span class="pl-c1">sqrt</span>()
<span class="pl-s1">sqrt_one_minus_alpha_bar</span> <span class="pl-c1">=</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar</span>).<span class="pl-c1">sqrt</span>()

<span class="pl-s1">timestep</span> <span class="pl-c1">=</span> <span class="pl-c1">200</span>
<span class="pl-s1">x_t</span> <span class="pl-c1">=</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">timestep</span>)
<span class="pl-s1">torchvision</span>.<span class="pl-c1">io</span>.<span class="pl-c1">write_png</span>(<span class="pl-en">transform_reverse</span>(<span class="pl-s1">x_t</span>).<span class="pl-c1">clip</span>(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>).<span class="pl-c1">cpu</span>(), <span class="pl-s">'%s.png'</span> <span class="pl-c1">%</span> <span class="pl-s1">timestep</span>)</pre></div>
<p>;;;e;;;c其中$\bar{\alpha}_t = \prod_{i = 1}^{t}\alpha_i$。由于式(6)中存在着两个完全随机的标准高斯分布，因此可以对这二者进行重参数化技巧的逆运算得到式(7)，再通过<code class="notranslate">高斯分布的加法法则</code>得到式(8)，从而对多步的迭代进行化简，能够仅仅使用一步求出正向过程的任意时刻的状态：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">t</span>):
    <span class="pl-c">#式(10)的一步增噪过程</span>
    <span class="pl-k">return</span> <span class="pl-s1">sqrt_alpha_bar</span>[<span class="pl-s1">t</span>] <span class="pl-c1">*</span> <span class="pl-s1">x_0</span> <span class="pl-c1">+</span> <span class="pl-s1">sqrt_one_minus_alpha_bar</span>[<span class="pl-s1">t</span>] <span class="pl-c1">*</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span><span class="pl-s1">x_0</span>.<span class="pl-c1">shape</span>).<span class="pl-c1">cuda</span>()

<span class="pl-c">#对参数的预先缓存</span>
<span class="pl-s1">alpha</span> <span class="pl-c1">=</span> <span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">beta</span>
<span class="pl-c">#在这里，对求得的α累乘的最前位置，额外加了一个1，这是为了编写程序时，时间戳与索引的一致</span>
<span class="pl-s1">alpha_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">cat</span>((<span class="pl-s1">torch</span>.<span class="pl-c1">Tensor</span>((<span class="pl-c1">1</span>,)).<span class="pl-c1">cuda</span>(), <span class="pl-s1">alpha</span>.<span class="pl-c1">cumprod</span>(<span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">0</span>)))
<span class="pl-s1">sqrt_alpha_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">alpha_bar</span>.<span class="pl-c1">sqrt</span>()
<span class="pl-s1">sqrt_one_minus_alpha_bar</span> <span class="pl-c1">=</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar</span>).<span class="pl-c1">sqrt</span>()

<span class="pl-s1">timestep</span> <span class="pl-c1">=</span> <span class="pl-c1">200</span>
<span class="pl-s1">x_t</span> <span class="pl-c1">=</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">timestep</span>)
<span class="pl-s1">torchvision</span>.<span class="pl-c1">io</span>.<span class="pl-c1">write_png</span>(<span class="pl-en">transform_reverse</span>(<span class="pl-s1">x_t</span>).<span class="pl-c1">clip</span>(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>).<span class="pl-c1">cpu</span>(), <span class="pl-s">'%s.png'</span> <span class="pl-c1">%</span> <span class="pl-s1">timestep</span>)</pre></div>
<p>;;;c;;;e</p>
<h2>Reverse Process</h2>
<p>Compared to the forward process, the reverse process is much more complex. The goal of the inverse process is to obtain a probabilistic model for a given $x_T \sim p_\theta(x_T) = \mathcal{N}(0, I)$, such that $x_T$ can be transformed from a standard Gaussian distribution into a likelihood estimate of the original data set, i.e.:;;;e;;;c</p>
<h2>逆向过程</h2>
<p>相较正向过程，逆向过程则会复杂很多。逆向过程的目标是对于给定的$x_T \sim p_\theta(x_T) = \mathcal{N}(0, I)$，需要一个概率模型，能够使得$x_T$由标准高斯分布，转变为原始数据集的似然估计，即：;;;c</p>
<p>$$
p_\theta(x_0|x_T) = p_\theta(x_T)\prod^T_{t = 1}p_\theta(x_{t - 1}|x_t)
\tag{11}
$$</p>
<p>;;;eIf we perform maximum likelihood estimation, the log loss is:;;;e;;;c若对其进行极大似然估计，其对数损失为：;;;c</p>
<p>$$
L_\theta = -\log p_\theta(x_0) = -\log (p_\theta(x_T)\prod^T_{t = 1}p_\theta(x_{t - 1}|x_t))
\tag{12}
$$</p>
<p>;;;ewhere $p_\theta(x_t|x_{t + 1})$ is completely unknown and cannot be solved, so we consider making <code class="notranslate">The upper bound of this loss as small as possible</code>. Since the KL divergence is necessarily non-negative, we have:;;;e;;;c其中，$p_\theta(x_t|x_{t + 1})$是完全未知的，无法求解，因此考虑令该损失的<code class="notranslate">上界尽可能的小</code>。由于KL散度必然是非负的，所以：;;;c</p>
<p>$$
\begin{align}
L_\theta \leq L_{VLB} &amp;= -\log p_\theta(x_0) + D_{KL}(q(x_{1:T}|x_0)||p_\theta(x_{1:T}|x_0))
\tag{13}
\\
&amp;= -\log p_\theta(x_0) + E_{q(x_{1:T}|x_0)}\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{1:T}|x_0)}
\tag{14}
\end{align}
$$</p>
<p>;;;eAccording to <code class="notranslate">Bayes' theorem</code>:;;;e;;;c根据<code class="notranslate">贝叶斯定理</code>：;;;c</p>
<p>$$
p_\theta(x_{1:T}|x_0) = \frac{p_\theta(x_0|x_{1:T})p_\theta(x_{1:T})}{p_\theta(x_0)} = \frac{p_\theta(x_0, x_{1:T})}{p_\theta(x_0)} = \frac{p_\theta(x_{0:T})}{p_\theta(x_0)}
\tag{15}
$$</p>
<p>;;;eTherefore:;;;e;;;c因此：;;;c</p>
<p>$$
\begin{align}
L_{VLB} &amp;= -\log p_\theta(x_0) + E_{q(x_{1:T}|x_0)}\log\frac{q(x_{1:T}|x_0)p_\theta(x_0)}{p_\theta(x_{0:T})}
\tag{16}
\\
&amp;= -\log p_\theta(x_0) + E_{q(x_{1:T}|x_0)}\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} + E_{q(x_{1:T}|x_0)} \log p_\theta(x_0)
\tag{17}
\\
&amp;= -\log p_\theta(x_0) + E_{q(x_{1:T}|x_0)}\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} + \log p_\theta(x_0)
\tag{18}
\\
&amp;= E_{q(x_{1:T}|x_0)}\log\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}
\tag{19}
\\
&amp;= E_{q(x_{1:T}|x_0)}\log\frac{\prod^T_{t = 1}q(x_t|x_{t - 1})}{p_\theta(x_T)\prod^T_{t = 1}p_\theta(x_{t - 1}|x_t)}
\tag{20}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \sum^T_{t = 1} \log \frac{q(x_t|x_{t - 1})}{p_\theta(x_{t - 1}|x_t)}]
\tag{21}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \log \frac{q(x_1|x_0)}{p_\theta(x_{0}|x_1)} + \sum^T_{t = 2} \log \frac{q(x_t|x_{t - 1})}{p_\theta(x_{t - 1}|x_t)}]
\tag{22}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \log \frac{q(x_1|x_0)}{p_\theta(x_{0}|x_1)} + \sum^T_{t = 2} \log \frac{q(x_{t - 1}|x_t, x_0)q(x_t|x_0)}{p_\theta(x_{t - 1}|x_t)q(x_{t - 1}|x_0)}]
\tag{23}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \log \frac{q(x_1|x_0)}{p_\theta(x_{0}|x_1)} + \sum^T_{t = 2} \log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}
\\
&amp;\quad +  \sum^T_{t = 2} \log \frac{q(x_t|x_0)}{q(x_{t - 1}|x_0)}]
\tag{24}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \log \frac{q(x_1|x_0)}{p_\theta(x_{0}|x_1)} + \sum^T_{t = 2} \log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}
\\
&amp;\quad + \log \frac{q(x_T|x_0)q(x_{T - 1}|x_0)\dots q(x_2|x_0)}{q(x_{T - 1}|x_0)q(x_{T - 2}|x_0)\dots q(x_1|x_0)}]
\tag{25}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \log \frac{q(x_1|x_0)}{p_\theta(x_{0}|x_1)} + \sum^T_{t = 2} \log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}
\\
&amp;\quad + \log \frac{q(x_T|x_0)}{q(x_1|x_0)}]
\tag{26}
\\
&amp;= E_{q(x_{1:T}|x_0)}[-\log p_\theta(x_T) + \log \frac{q(x_T|x_0)}{p_\theta(x_{0}|x_1)} + \sum^T_{t = 2} \log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}]
\tag{27}
\\
&amp;= E_{q(x_{1:T}|x_0)}[\log \frac{q(x_T|x_0)}{p_\theta(x_T)} - \log p_\theta(x_{0}|x_1) + \sum^T_{t = 2} \log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}]
\tag{28}
\\
&amp;= E_{q(x_T|x_0)}\log \frac{q(x_T|x_0)}{p_\theta(x_T)} - E_{q(x_1|x_0)}\log p_\theta(x_{0}|x_1) + \sum^T_{t = 2} E_{q(x_t, x_{t - 1}|x_0)}\log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}
\tag{29}
\end{align}
$$</p>
<p>;;;eAlso:;;;e;;;c又：;;;c</p>
<p>$$
\begin{align}
&amp;q(x_{t - 1}|x_t, x_0) = \frac{q(x_{t - 1}, x_t, x_0)}{q(x_t, x_0)} = \frac{q(x_{t - 1}, x_t| x_0)}{q(x_t, x_0)}
\tag{30}
\\
\Leftrightarrow &amp;q(x_{t - 1}, x_t| x_0) = q(x_t, x_0)q(x_{t - 1}|x_t, x_0)
\tag{31}
\end{align}
$$</p>
<p>;;;eSo:;;;e;;;c从而：;;;c</p>
<p>$$
\begin{align}
L_{VLB} &amp;= E_{q(x_T|x_0)}\log \frac{q(x_T|x_0)}{p_\theta(x_T)} - E_{q(x_1|x_0)}\log p_\theta(x_{0}|x_1)
\\
&amp;\quad + \sum^T_{t = 2} E_{q(x_t, x_0)}E_{q(x_{t - 1}|x_t, x_0)}\log \frac{q(x_{t - 1}|x_t, x_0)}{p_\theta(x_{t - 1}|x_t)}
\tag{32}
\\
&amp;= \underbrace{D_{KL}(q(x_T|x_0)||p_\theta(x_T))}_{L_T}
\\
&amp;\quad \underbrace{- E_{q(x_1|x_0)}\log p_\theta(x_{0}|x_1)}_{L_0}
\\
&amp;\quad + \underbrace{\sum^T_{t = 2} E_{q(x_t, x_0)}D_{KL}(q(x_{t - 1}|x_t, x_0)||p_\theta(x_{t - 1}|x_t))}_{L_{t - 1}}
\tag{33}
\end{align}
$$</p>
<p>;;;ewhere, for $L_T$, since $q(x_T) = \mathcal{N}(0, I)$ and $p_\theta(x_T) = \mathcal{N}(0, I)$ are both independent of the maximum likelihood estimation parameters, they are regarded as constants.</p>
<p>For $L_0$, since $1 = q(x_0|x_0) = \frac{q(x_1|x_0)q(x_0|x_0)}{q(x_1|x_0)} = q(x_0|x_1)$, we have:;;;e;;;c其中，对于$L_T$，由于$q(x_T) = \mathcal{N}(0, I)$，$p_\theta(x_T) = \mathcal{N}(0, I)$都和极大似然估计参数无关，视为常数；</p>
<p>对于$L_0$，由于$1 = q(x_0|x_0) = \frac{q(x_1|x_0)q(x_0|x_0)}{q(x_1|x_0)} = q(x_0|x_1)$，因此有：;;;c</p>
<p>$$
\begin{align}
L_0 &amp;= - E_{q(x_1|x_0)}\log p_\theta(x_{0}|x_1)
\tag{34}
\\
&amp;= E_{q(x_1|x_0)}E_{q(x_0|x_1)}[q(x_0|x_1) \log q(x_0|x_0) - q(x_0|x_1) \log p_\theta(x_{0}|x_1)]
\tag{35}
\\
&amp;= E_{q(x_1, x_0)}D_{KL}(q(x_{1 - 1}|x_1, x_0)||p_\theta(x_{1 - 1}|x_0))
\tag{36}
\end{align}
$$</p>
<p>;;;eSimilar to the form of $L_{t - 1}$, let $L_0 + L_{t - 1} = L_t$. For the posterior distribution $q(x_{t - 1}|x_t)$ of the forward process $q(x_t|x_{t - 1})$ in the equation, by Bayes' theorem:;;;e;;;c与$L_{t - 1}$形式相同，记$L_0 + L_{t - 1} = L_t$，对于式中的正向过程$q(x_t|x_{t - 1})$的后验分布$q(x_{t - 1}|x_t)$，由贝叶斯定理：;;;c</p>
<p>$$
q(x_{t - 1}|x_t) = \frac{q(x_t|x_{t - 1})q(x_{t - 1})}{q(x_t)} = \frac{q(x_t|x_{t - 1})q(x_{t - 1}|x_0)}{q(x_t|x_0)}
\tag{37}
$$</p>
<p>;;;eThe three probabilities in equation (37) are known and can be solved. Let the posterior distribution be $q(x_{t - 1}|x_t) = \mathcal{N}(\tilde{\mu}, \Sigma)$. Considering the exponential part of equation (37) expanded using the Gaussian distribution density function, we have:;;;e;;;c式(37)的三个概率都是已知的，必然可以求解，设后验分布$q(x_{t - 1}|x_t) = \mathcal{N}(\tilde{\mu}, \Sigma)$，考虑式(37)使用高斯分布密度函数展开后的指数部分，则有：;;;c</p>
<p>$$
\begin{align}
\frac{(x_{t - 1} - \tilde{\mu})^2}{\Sigma} &amp;= \frac{(x_t - \sqrt{\alpha_t}x_{t - 1})^2}{1 - \alpha_t} + \frac{(x_{t - 1} - \sqrt{\bar{\alpha}_{t - 1}}x_0)^2}{1 - \bar{\alpha}_{t - 1}} - \frac{(x_t - \sqrt{\bar{\alpha}_t}x_0)^2}{1 - \bar{\alpha}_t}
\tag{38}
\\
&amp;= (\underbrace{\frac{\alpha_t}{1 - \alpha_t} + \frac{1}{1 - \bar{\alpha}_{t - 1}}}_{1/\Sigma})x^2_{t - 1} - 2(\underbrace{\frac{\sqrt{\alpha_t}}{1 - \alpha_t}x_t + \frac{\sqrt{\bar{\alpha}_{t - 1}}}{1 - \bar{\alpha}_{t - 1}}x_0}_{\tilde{\mu}/\Sigma})x_{t - 1} + C(x_0, x_t)
\tag{39}
\end{align}
$$</p>
<p>;;;ewhere $C(x_0, x_t)$ is the term that does not contain $x_{t - 1}$. Through left-right comparison, it is easy to obtain:;;;e;;;c其中，$C(x_0, x_t)$为不含$x_{t - 1}$的项，通过左右比对，易得：;;;c</p>
<p>$$
\begin{align}
\Sigma &amp;= \frac{1}{\frac{\alpha_t}{1 - \alpha_t} + \frac{1}{1 - \bar{\alpha}_{t - 1}}}
\tag{40}
\\
&amp;= \frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t
\tag{41}
\\
\tilde{\mu} &amp;= ((\frac{\sqrt{\alpha_t}}{1 - \alpha_t}x_t + \frac{\sqrt{\bar{\alpha}_{t - 1}}}{1 - \bar{\alpha}_{t - 1}}x_0)\Sigma
\tag{42}
\\
&amp;= \frac{(1 - \bar{\alpha}_{t - 1})\sqrt{\alpha_t}}{1 - \bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t - 1}}}{1 - \bar{\alpha}_t}\beta_tx_0
\tag{43}
\end{align}
$$</p>
<p>;;;eThen, from <code class="notranslate">Equation (10)</code>, $x_0$ can be converted to $x_t$ for expression, thus:;;;e;;;c又由<code class="notranslate">式(10)</code>，可将$x_0$转换为$x_t$来进行表达，从而：;;;c</p>
<p>$$
\begin{align}
\tilde{\mu} &amp;= \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1 - \alpha_t}{\sqrt{\alpha_t(1 - \bar{\alpha}_t)}}\epsilon_t(x_t, t)
\tag{44}
\\
x_{t - 1} &amp;= \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1 - \alpha_t}{\sqrt{\alpha_t(1 - \bar{\alpha}_t)}}\epsilon_t(x_t, t) + \sqrt{\frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t}\epsilon
\tag{45}
\end{align}
$$</p>
<p>;;;ewhere $\epsilon_t(x_t, t)$ denotes the noise required to transition from the initial state $x_0$ to the state $x_t$ at time $t$ through a single forward step. If we define $p_\theta(x_{t - 1}|x_t) = \mathcal{N}(\mu_\theta, \sigma^2_\theta)$, then by the <code class="notranslate">KL divergence formula for Gaussian distributions</code>:;;;e;;;c其中，$\epsilon_t(x_t, t)$的含义为，对于给定的时刻$t$，从初始状态$x_0$，经过一步的正向过程成为该时刻状态$x_t$，所需要的噪声。若定义$p_\theta(x_{t - 1}|x_t) = \mathcal{N}(\mu_\theta, \sigma^2_\theta)$，由<code class="notranslate">高斯分布的KL散度公式</code>：;;;c</p>
<p>$$
\begin{align}
L_t &amp;= \sum^T_{t = 1} E_{q(x_t, x_0)}D_{KL}(q(x_{t - 1}|x_t, x_0)||p_\theta(x_{t - 1}|x_t))
\tag{46}
\\
&amp;= \sum^T_{t = 1} E_{q(x_t, x_0)}[\frac{1}{2}\log\frac{\sigma^2_\theta}{\frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t} + \frac{\frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t + (\tilde{\mu} - \mu_\theta)^2}{2\sigma^2_\theta} - \frac{1}{2}]
\tag{47}
\end{align}
$$</p>
<p>;;;eAlthough $\sigma_\theta$ is learnable, its improvement in sampling quality is not significant and has not been widely adopted. In DDPM, we set $\sigma^2_\theta = \frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t$, so we have:;;;e;;;c尽管$\sigma_\theta$是可学习的，但其对采样质量的提升并不显著，未得到推广。在DDPM中，取$\sigma^2_\theta = \frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t$，因此有：;;;c</p>
<p>$$
L_t = \sum^T_{t = 1} E_{q(x_t, x_0)}[\frac{1 - \bar{\alpha}_t}{2(1 - \bar{\alpha}_{t - 1})\beta_t}(\tilde{\mu} - \mu_\theta)^2]
\tag{48}
$$</p>
<p>;;;eTo minimize $L_t$, it is necessary for $\mu_\theta$ to be as close as possible to $\tilde{\mu}$. If we set $\mu_\theta = \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1 - \alpha_t}{\sqrt{\alpha_t(1 - \bar{\alpha}_t)}}\epsilon_\theta(x_t, t)$, then we only need $\epsilon_\theta(x_t, t)$ to be as close as possible to $\epsilon_t(x_t, t)$, i.e., the loss function:;;;e;;;c要使$L_t$尽可能小，即需要$\mu_\theta$尽可能接近$\tilde{\mu}$。若令$\mu_\theta = \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1 - \alpha_t}{\sqrt{\alpha_t(1 - \bar{\alpha}_t)}}\epsilon_\theta(x_t, t)$，那么只需要$\epsilon_\theta(x_t, t)$尽可能接近$\epsilon_t(x_t, t)$，即损失函数：;;;c</p>
<p>$$
L = ||\epsilon_\theta(x_t, t) - \epsilon_t(x_t, t)||^2_2
\tag{49}
$$</p>
<p>;;;eSampling formula for the reverse process:;;;e;;;c逆向过程的采样公式：;;;c</p>
<p>$$
x_{t - 1} = \frac{1}{\sqrt{\alpha_t}}x_t - \frac{1 - \alpha_t}{\sqrt{\alpha_t(1 - \bar{\alpha}_t)}}\epsilon_\theta(x_t, t) + \sqrt{\frac{1 - \bar{\alpha}_{t - 1}}{1 - \bar{\alpha}_t}\beta_t}\epsilon
\tag{50}
$$</p>
<p>;;;e</p>
<h2>Network Setup</h2>
<p>After a lengthy process of reverse derivation, the loss function of the diffusion model was obtained. The next step is to build a network for the prediction function, whose input is a certain time point and the corresponding noisy image at that time point, and whose output is the predicted noise required to transform the initial state into the state at that time point through the forward process. DDPM uses <code class="notranslate">UNet</code> to perform this process.</p>
<h3>Network Structure</h3>
<p>The original article provides a structural diagram of UNet:;;;e;;;c</p>
<h2>网络搭建</h2>
<p>经过逆向过程漫长的推导，获得了扩散模型的损失函数，接下来就是要对预测函数进行网络搭建，该预测函数的输入为某一时刻以及该时刻对应的带噪图片，输出为预测的，从初始状态，经过正向过程成为该时刻状态，所需要的噪声。DDPM采用了<code class="notranslate">UNet</code>来进行这个过程。</p>
<h3>网络结构</h3>
<p>原文章中给出了一个UNet的结构图：;;;c</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/u-net-illustration-correct-scale2.png"/></p></p>
<p>;;;eIn this case, the upper part of the square represents the number of data channels, and the lower left part represents the data resolution. The network inputs a $572^2$ resolution image with 1 channel and outputs a $388^2$ resolution image with 2 channels. The network contains four core components: ordinary convolution process, downsampling, upsampling, and residual process.</p>
<ul>
<li>The short arrow pointing to the right represents the standard convolution process, where in each layer, the first convolution operation always reduces the number of channels in the data to the predefined number of channels for that layer;</li>
<li>The downward arrow represents downsampling, during which the resolution of the data is always reduced to half of its original value, followed by deeper convolution operations;</li>
<li>The upward arrow represents upsampling, where the resolution of the data is always doubled, followed by convolution at a shallower layer;</li>
<li>The long right arrow represents the residual process, which utilizes the <code class="notranslate">Residual idea</code> to combine downsampled data with upsampled data before convolution, effectively mitigating information loss caused by downsampling.</li>
</ul>
<p>However, for diffusion models, the input requires an additional timestamp t in addition to a single image. Therefore, the image and timestamp must be integrated and fed into UNet for computation. This operation is also known as time embedding.</p>
<h3>Time Embedding</h3>
<p>The time embedding algorithm refers to the position embedding algorithm in <code class="notranslate">Attention is All You Need</code>. It expands the single number of the timestamp into a tensor, inputs it into the network for calculation, and then adds it to the ordinary convolution process for further calculation. The expansion of the timestamp obeys the following equation:;;;e;;;c在该案例中，方块的上方代表着数据的通道数，左下方代表着数据的分辨率。网络的输入为$572^2$分辨率、通道数为1的图片，输出为$388^2$分辨率、通道数为2的图片。在网络内，则包含了四个核心部分：普通卷积过程；下采样；上采样以及残差过程。</p>
<ul>
<li>向右的短箭头代表着普通卷积过程，在每一层中，第一次卷积过程总是会将数据的通道数变为预定的、该层的通道数；</li>
<li>向下的箭头代表着下采样，在这个过程中，总是会将数据的分辨率变为原来的一半，并在接下来进行更深层的卷积；</li>
<li>向上的箭头代表着上采样，在这个过程中，总是会将数据的分辨率变为原来的两倍，并在接下来进行更浅层的卷积；</li>
<li>向右的长箭头代表着残差过程，该部分利用了<code class="notranslate">残差思想</code>，将下采样的数据与上采样的数据相结合再进行卷积，能够有效地去除一些由于下采样导致的信息丢失问题。</li>
</ul>
<p>但是对于扩散模型而言，其输入还需要额外引入一个时间戳t，而非单单一个图片，因此还需要将图片和时间戳整合到一起，放入UNet中进行计算，这个操作又称时间嵌入。</p>
<h3>时间嵌入</h3>
<p>时间嵌入算法参考了<code class="notranslate">Attention is All You Need</code>中的位置嵌入算法，通过将时间戳这单个数字，展开为某个张量，再输入到网络中进行计算，最后再与普通卷积过程的只相加，进行接下来的计算。时间戳的展开服从下面的式子：;;;c</p>
<p>$$
\begin{align}
TE_{(t, i)} &amp;= \sin\frac{t}{10000^{2i / d}}
\tag{51}
\\
TE_{(t, j)} &amp;= \cos\frac{t}{10000^{2j / d}}
\tag{52}
\end{align}
$$</p>
<p>;;;ewhere $d$ denotes the desired dimension of expansion, $i = {1, 2, \dots, \frac{d}{2}}$, and $j = {\frac{d}{2} + 1, \frac{d}{2} + 2, \dots, d}$. If $d = 128$ is defined, its visualization is shown in the figure below:;;;e;;;c其中，$d$表示所期望的展开维度，$i = \{1, 2, \dots, \frac{d}{2}\}$，$j = \{\frac{d}{2} + 1, \frac{d}{2} + 2, \dots, d\}$。若定义$d = 128$，则其可视化如下图所示：;;;c</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/time_embeddings.png"/></p></p>
<p>;;;eIf represented as function graphs, the red $TE_{(t, i)}$ and blue $TE_{(t, j)}$ change with dimension as shown below:;;;e;;;c若是以函数图像的形式表示，红色的$TE_{(t, i)}$与蓝色的$TE_{(t, j)}$随着维度的变化如下所示：;;;c</p>
<p><p align="center"><iframe src="https://www.desmos.com/calculator/xkmphum0ou?embed" width="800" height="400" style="border: 1px solid #ccc" frameborder=0></iframe></p><br>
;;;e</p>
<h2>Training Process</h2>
<p>First, import some necessary libraries:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">import</span> <span class="pl-s1">time</span>
<span class="pl-k">from</span> <span class="pl-s1">pathlib</span> <span class="pl-k">import</span> <span class="pl-v">Path</span>

<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>.<span class="pl-s1">nn</span>.<span class="pl-s1">functional</span> <span class="pl-k">as</span> <span class="pl-c1">F</span>
<span class="pl-k">import</span> <span class="pl-s1">torchvision</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span> <span class="pl-k">import</span> <span class="pl-s1">optim</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span>.<span class="pl-s1">utils</span>.<span class="pl-s1">data</span> <span class="pl-k">import</span> <span class="pl-v">DataLoader</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span> <span class="pl-k">import</span> <span class="pl-s1">datasets</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">transforms</span>.<span class="pl-s1">v2</span> <span class="pl-k">import</span> <span class="pl-v">Lambda</span>, <span class="pl-v">ToTensor</span>, <span class="pl-v">RandomHorizontalFlip</span>, <span class="pl-v">Compose</span>, <span class="pl-v">Grayscale</span>
<span class="pl-k">from</span> <span class="pl-s1">tqdm</span> <span class="pl-k">import</span> <span class="pl-s1">tqdm</span>

<span class="pl-k">import</span> <span class="pl-s1">unet</span></pre></div>
<p>Next is the determination of training configurations and hyperparameters. For hyperparameters such as $\beta_t$, select the linear noise schedule:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">linear</span>(<span class="pl-s1">time_steps</span>):
    <span class="pl-s1">beta_start</span> <span class="pl-c1">=</span> <span class="pl-c1">0.0001</span>
    <span class="pl-s1">beta_end</span> <span class="pl-c1">=</span> <span class="pl-c1">0.02</span>
    <span class="pl-k">return</span> <span class="pl-s1">torch</span>.<span class="pl-c1">linspace</span>(<span class="pl-s1">beta_start</span>, <span class="pl-s1">beta_end</span>, <span class="pl-s1">time_steps</span>).<span class="pl-c1">cuda</span>()


<span class="pl-c">#The timestamp is set from 0 to 1000.</span>
<span class="pl-c">#Reducing or increasing this value will change the parameters related to the noise schedule.</span>
<span class="pl-s1">time_steps</span> <span class="pl-c1">=</span> <span class="pl-c1">1000</span>
<span class="pl-c">#Pre-computed cache of noise schedule-related parameters.</span>
<span class="pl-c">#Shape:[1000]</span>
<span class="pl-s1">betas</span> <span class="pl-c1">=</span> <span class="pl-en">linear</span>(<span class="pl-s1">time_steps</span>)
<span class="pl-c">#Shape:[1000]</span>
<span class="pl-s1">alphas</span> <span class="pl-c1">=</span> <span class="pl-c1">1.</span> <span class="pl-c1">-</span> <span class="pl-s1">betas</span>
<span class="pl-c">#Shape:[1001]</span>
<span class="pl-s1">alphas_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">cat</span>((<span class="pl-s1">torch</span>.<span class="pl-c1">tensor</span>((<span class="pl-c1">1</span>,)).<span class="pl-c1">cuda</span>(), <span class="pl-s1">torch</span>.<span class="pl-c1">cumprod</span>(<span class="pl-s1">input</span><span class="pl-c1">=</span><span class="pl-s1">alphas</span>, <span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">0</span>)))
<span class="pl-c">#Shape:[1001]</span>
<span class="pl-s1">sqrt_alphas_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">sqrt</span>(<span class="pl-s1">alphas_bar</span>)
<span class="pl-c">#Shape:[1001]</span>
<span class="pl-s1">sqrt_one_minus_alphas_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">sqrt</span>(<span class="pl-c1">1.</span> <span class="pl-c1">-</span> <span class="pl-s1">alphas_bar</span>)</pre></div>
<p>Configuration and hyperparameters:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-s">"""</span>
<span class="pl-s">For simplicity, CIFAR1 is used as the dataset, with image dimensions of 32×32.</span>
<span class="pl-s">CIFAR1 refers to using only one category from CIFAR10 as the dataset.</span>
<span class="pl-s">The file structure of the dataset is as follows:</span>
<span class="pl-s">cifar1</span>
<span class="pl-s">├── test</span>
<span class="pl-s">│   └── horse</span>
<span class="pl-s">│       ├── 0001.png</span>
<span class="pl-s">│       ├── 0002.png</span>
<span class="pl-s">│       ├── ...</span>
<span class="pl-s">│       └── 5000.png</span>
<span class="pl-s">└── train</span>
<span class="pl-s">    └── horse</span>
<span class="pl-s">        ├── 0001.png</span>
<span class="pl-s">        ├── 0002.png</span>
<span class="pl-s">        ├── ...</span>
<span class="pl-s">        └── 1000.png</span>
<span class="pl-s">"""</span>
<span class="pl-s1">image_size</span> <span class="pl-c1">=</span> <span class="pl-c1">32</span>
<span class="pl-c">#The number of channels is 3, i.e., RGB.</span>
<span class="pl-s1">channels</span> <span class="pl-c1">=</span> <span class="pl-c1">3</span>
<span class="pl-c">#The number of base channels in the model, i.e., the number of channels in the top layer.</span>
<span class="pl-s1">base_channels</span> <span class="pl-c1">=</span> <span class="pl-c1">128</span>
<span class="pl-c">#The number of channels in different layers of the model,</span>
<span class="pl-c">#with a resolution of 32×32, the model depth is selected as 4,</span>
<span class="pl-c">#corresponding to 128, 256, 256, 256 channels.</span>
<span class="pl-s1">ch_mults</span> <span class="pl-c1">=</span> {
    <span class="pl-c1">32</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>),
    <span class="pl-c1">64</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>),
    <span class="pl-c1">128</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>),
    <span class="pl-c1">256</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">4</span>, <span class="pl-c1">4</span>),
    <span class="pl-c1">512</span>: (<span class="pl-c1">0.5</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">4</span>, <span class="pl-c1">4</span>)
}
<span class="pl-c">#Learning rate.</span>
<span class="pl-s1">learning_rate</span> <span class="pl-c1">=</span> <span class="pl-c1">1e-4</span>
<span class="pl-c">#Training rounds: Select the iterative dataset 500 times</span>
<span class="pl-c">#(in reality, this number of rounds is far from sufficient).</span>
<span class="pl-s1">epochs</span> <span class="pl-c1">=</span> <span class="pl-c1">500</span>
<span class="pl-c">#Rounds used for sampling and model checkpoint saving.</span>
<span class="pl-s1">milestone_step</span> <span class="pl-c1">=</span> <span class="pl-c1">10</span>
<span class="pl-c">#Maximum number of checkpoints saved.</span>
<span class="pl-s1">cache_num</span> <span class="pl-c1">=</span> <span class="pl-c1">10</span>
<span class="pl-c">#The number of images trained in a batch.</span>
<span class="pl-c">#In this case, 128 images are suitable for a graphics card with 8G of memory.</span>
<span class="pl-s1">batch_size</span> <span class="pl-c1">=</span> <span class="pl-c1">128</span>
<span class="pl-c">#Proposed locations for checkpoints.</span>
<span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">=</span> <span class="pl-s">'cifar1/cp'</span>
<span class="pl-c">#Location of training set.</span>
<span class="pl-s1">datasets_folder</span> <span class="pl-c1">=</span> <span class="pl-s">'cifar1/train'</span>
<span class="pl-c">#File used to collect loss values during training.</span>
<span class="pl-s1">csv_str</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">'/loss.csv'</span>
<span class="pl-c">#Prefix for model checkpoint save file names.</span>
<span class="pl-s1">prefix</span> <span class="pl-c1">=</span> <span class="pl-s">"checkpoint_epoch"</span>
<span class="pl-c">#suffix for model checkpoint save file names.</span>
<span class="pl-s1">suffix</span> <span class="pl-c1">=</span> <span class="pl-s">".pth"</span>
<span class="pl-c">#Create a new folder for checkpoints.</span>
<span class="pl-en">Path</span>(<span class="pl-s1">checkpoint_folder</span>).<span class="pl-c1">mkdir</span>(<span class="pl-s1">exist_ok</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
<span class="pl-en">Path</span>(<span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">'/milestone'</span>).<span class="pl-c1">mkdir</span>(<span class="pl-s1">exist_ok</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
<span class="pl-c">#Create a new model.</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">unet</span>.<span class="pl-c1">UNetModel</span>(
    <span class="pl-s1">image_size</span><span class="pl-c1">=</span><span class="pl-s1">image_size</span>,
    <span class="pl-s1">in_channels</span><span class="pl-c1">=</span><span class="pl-s1">channels</span>,
    <span class="pl-s1">model_channels</span><span class="pl-c1">=</span><span class="pl-s1">base_channels</span>,
    <span class="pl-s1">out_channels</span><span class="pl-c1">=</span><span class="pl-s1">channels</span>,
    <span class="pl-s1">num_res_blocks</span><span class="pl-c1">=</span><span class="pl-c1">2</span>,
    <span class="pl-s1">attention_resolutions</span><span class="pl-c1">=</span>(<span class="pl-c1">32</span>, <span class="pl-c1">16</span>, <span class="pl-c1">8</span>),
    <span class="pl-s1">dropout</span><span class="pl-c1">=</span><span class="pl-c1">0.0</span>,
    <span class="pl-s1">channel_mult</span><span class="pl-c1">=</span><span class="pl-s1">ch_mults</span>[<span class="pl-s1">image_size</span>],
    <span class="pl-s1">num_heads</span><span class="pl-c1">=</span><span class="pl-c1">4</span>,
    <span class="pl-s1">num_head_channels</span><span class="pl-c1">=</span><span class="pl-c1">-</span><span class="pl-c1">1</span>,
)
<span class="pl-c">#If there are checkpoints in the checkpoints folder, read the latest checkpoint.</span>
<span class="pl-s1">last_model</span> <span class="pl-c1">=</span> <span class="pl-c1">None</span>
<span class="pl-s1">last</span> <span class="pl-c1">=</span> <span class="pl-c1">0</span>
<span class="pl-k">for</span> <span class="pl-s1">file</span> <span class="pl-c1">in</span> <span class="pl-s1">os</span>.<span class="pl-c1">listdir</span>(<span class="pl-s1">checkpoint_folder</span>):
    <span class="pl-k">if</span> <span class="pl-s1">file</span>[:<span class="pl-en">len</span>(<span class="pl-s1">prefix</span>)] <span class="pl-c1">!=</span> <span class="pl-s1">prefix</span>:
        <span class="pl-k">continue</span>
    <span class="pl-s1">epochs_str</span> <span class="pl-c1">=</span> <span class="pl-s1">file</span>[<span class="pl-en">len</span>(<span class="pl-s1">prefix</span>) <span class="pl-c1">+</span> <span class="pl-c1">1</span>:<span class="pl-c1">0</span> <span class="pl-c1">-</span> <span class="pl-en">len</span>(<span class="pl-s1">suffix</span>)]
    <span class="pl-k">if</span> <span class="pl-en">int</span>(<span class="pl-s1">epochs_str</span>) <span class="pl-c1">&gt;</span> <span class="pl-s1">last</span>:
        <span class="pl-s1">last</span> <span class="pl-c1">=</span> <span class="pl-en">int</span>(<span class="pl-s1">epochs_str</span>)
<span class="pl-k">if</span> <span class="pl-s1">last</span> <span class="pl-c1">&gt;</span> <span class="pl-c1">0</span>:
    <span class="pl-s1">last_model</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">load</span>(<span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/%s_%d%s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">prefix</span>, <span class="pl-s1">last</span>, <span class="pl-s1">suffix</span>), <span class="pl-s1">weights_only</span><span class="pl-c1">=</span><span class="pl-c1">False</span>)
<span class="pl-k">if</span> <span class="pl-s1">last_model</span> <span class="pl-c1"><span class="pl-c1">is</span> <span class="pl-c1">not</span></span> <span class="pl-c1">None</span>:
    <span class="pl-s1">model</span>.<span class="pl-c1">load_state_dict</span>(<span class="pl-s1">last_model</span>)
<span class="pl-k">else</span>:
    <span class="pl-en">print</span>(<span class="pl-s">"No Checkpoints Exist"</span>)
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-c1">cuda</span>()
<span class="pl-c">#Parameter count in computational models.</span>
<span class="pl-s1">parameters</span> <span class="pl-c1">=</span> <span class="pl-en">sum</span>(<span class="pl-s1">p</span>.<span class="pl-c1">numel</span>() <span class="pl-k">for</span> <span class="pl-s1">p</span> <span class="pl-c1">in</span> <span class="pl-s1">model</span>.<span class="pl-c1">parameters</span>() <span class="pl-k">if</span> <span class="pl-s1">p</span>.<span class="pl-c1">requires_grad</span>)
<span class="pl-s1">count_str</span> <span class="pl-c1">=</span> <span class="pl-s">"Parameters Count: "</span>
<span class="pl-en">print</span>(<span class="pl-s1">count_str</span> <span class="pl-c1">+</span> <span class="pl-s">"%.2fB"</span> <span class="pl-c1">%</span> (<span class="pl-s1">parameters</span> <span class="pl-c1">/</span> <span class="pl-c1">1e9</span>)) \
    <span class="pl-k">if</span> <span class="pl-s1">parameters</span> <span class="pl-c1">&gt;</span> <span class="pl-c1">1e9</span> <span class="pl-k">else</span> <span class="pl-en">print</span>(<span class="pl-s1">count_str</span> <span class="pl-c1">+</span> <span class="pl-s">"%.2fM"</span> <span class="pl-c1">%</span> (<span class="pl-s1">parameters</span> <span class="pl-c1">/</span> <span class="pl-c1">1e6</span>))
<span class="pl-c">#Optimizer.</span>
<span class="pl-s1">optimizer</span> <span class="pl-c1">=</span> <span class="pl-s1">optim</span>.<span class="pl-c1">AdamW</span>(<span class="pl-s1">model</span>.<span class="pl-c1">parameters</span>(), <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-s1">learning_rate</span>, <span class="pl-s1">weight_decay</span><span class="pl-c1">=</span><span class="pl-c1">1e-4</span>)
<span class="pl-c">#Convert images to tensors.</span>
<span class="pl-s">"""</span>
<span class="pl-s">ToTensor()                    :</span>
<span class="pl-s">    Reads an image and scales its integers from [0, 255] to floating-point numbers in the range [0, 1]</span>
<span class="pl-s">Lambda(lambda t: (t * 2) - 1) : Scale floating-point numbers in the range [0, 1] to the range [-1, 1]</span>
<span class="pl-s">RandomHorizontalFlip()        : Randomly flip the data horizontally</span>
<span class="pl-s">"""</span>
<span class="pl-s1">transform</span> <span class="pl-c1">=</span> <span class="pl-en">Compose</span>(
    [<span class="pl-en">Grayscale</span>(), <span class="pl-en">ToTensor</span>(), <span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">*</span> <span class="pl-c1">2</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>), <span class="pl-en">RandomHorizontalFlip</span>()]
    <span class="pl-k">if</span> <span class="pl-s1">channels</span> <span class="pl-c1">==</span> <span class="pl-c1">1</span> <span class="pl-k">else</span>
    [<span class="pl-en">ToTensor</span>(), <span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">*</span> <span class="pl-c1">2</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>), <span class="pl-en">RandomHorizontalFlip</span>()]
)</pre></div>
<p>Core training methods:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">train</span>():
    <span class="pl-en">train_loop</span>(<span class="pl-en">DataLoader</span>(
        <span class="pl-s1">datasets</span>.<span class="pl-c1">ImageFolder</span>(<span class="pl-s1">datasets_folder</span>, <span class="pl-s1">transform</span><span class="pl-c1">=</span><span class="pl-s1">transform</span>),
        <span class="pl-s1">batch_size</span><span class="pl-c1">=</span><span class="pl-s1">batch_size</span>,
        <span class="pl-s1">shuffle</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
        <span class="pl-s1">drop_last</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
        <span class="pl-s1">pin_memory</span><span class="pl-c1">=</span><span class="pl-c1">True</span>
    ))


<span class="pl-k">def</span> <span class="pl-en">train_loop</span>(<span class="pl-s1">dataloader</span>):
    <span class="pl-c">#Calculate the number of iterations remaining.</span>
    <span class="pl-s1">local_epochs</span> <span class="pl-c1">=</span> <span class="pl-s1">epochs</span> <span class="pl-c1">-</span> <span class="pl-s1">last</span>
    <span class="pl-c">#Cache for loss value files.</span>
    <span class="pl-s1">csv_cache</span> <span class="pl-c1">=</span> <span class="pl-s">""</span>
    <span class="pl-en">print</span>()
    <span class="pl-en">print</span>(<span class="pl-s">"Now Strat Training"</span>)
    <span class="pl-k">for</span> <span class="pl-s1">epoch</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">local_epochs</span>):
        <span class="pl-c">#Loss value cache.</span>
        <span class="pl-s1">losses</span> <span class="pl-c1">=</span> []
        <span class="pl-c">#Without waiting, it seems that the tqdm progress bar will encounter some issues?</span>
        <span class="pl-s1">time</span>.<span class="pl-c1">sleep</span>(<span class="pl-c1">0.1</span>)
        <span class="pl-c">#Calculate the current iteration count.</span>
        <span class="pl-s1">global_epoch</span> <span class="pl-c1">=</span> <span class="pl-s1">epoch</span> <span class="pl-c1">+</span> <span class="pl-s1">last</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>
        <span class="pl-c">#Iterate through the dataset.</span>
        <span class="pl-k">for</span> <span class="pl-s1">step</span>, <span class="pl-s1">data_batch</span> <span class="pl-c1">in</span> (<span class="pl-s1">pbar</span> <span class="pl-c1">:=</span> <span class="pl-en">tqdm</span>(
                <span class="pl-en">enumerate</span>(<span class="pl-s1">dataloader</span>),
                <span class="pl-s1">total</span><span class="pl-c1">=</span><span class="pl-en">len</span>(<span class="pl-s1">dataloader</span>),
                <span class="pl-s1">desc</span><span class="pl-c1">=</span><span class="pl-s">"Epoch: %d/ %d With Loss %f"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">epochs</span>, <span class="pl-c1">1</span>)
        )):
            <span class="pl-c">#Initialization Optimizer.</span>
            <span class="pl-s1">optimizer</span>.<span class="pl-c1">zero_grad</span>()
            <span class="pl-c">#Get all data tensors for this batch,</span>
            <span class="pl-c">#with shape [batch_size, channels, image_size, image_size].</span>
            <span class="pl-s1">data_batch</span> <span class="pl-c1">=</span> <span class="pl-s1">data_batch</span>[<span class="pl-c1">0</span>].<span class="pl-c1">cuda</span>()
            <span class="pl-c">#Obtain the loss value and the timestamp randomly selected for calculating the loss value.</span>
            <span class="pl-s1">complex_loss</span>, <span class="pl-s1">t</span> <span class="pl-c1">=</span> <span class="pl-en">get_loss</span>(<span class="pl-s1">data_batch</span>)
            <span class="pl-s1">loss</span> <span class="pl-c1">=</span> <span class="pl-s1">complex_loss</span>.<span class="pl-c1">sum</span>() <span class="pl-c1">/</span> <span class="pl-c1">1000.</span>
            <span class="pl-s1">loss</span>.<span class="pl-c1">backward</span>()
            <span class="pl-s1">torch</span>.<span class="pl-c1">nn</span>.<span class="pl-c1">utils</span>.<span class="pl-c1">clip_grad_norm_</span>(<span class="pl-s1">model</span>.<span class="pl-c1">parameters</span>(), <span class="pl-c1">1.</span>)
            <span class="pl-s1">optimizer</span>.<span class="pl-c1">step</span>()
            <span class="pl-s1">pbar</span>.<span class="pl-c1">set_description</span>(<span class="pl-s">"Epoch: %d/ %d With Loss %f "</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">epochs</span>, <span class="pl-s1">loss</span>.<span class="pl-c1">item</span>()))
            <span class="pl-c">#Record the loss value for this batch.</span>
            <span class="pl-s1">losses</span>.<span class="pl-c1">append</span>(<span class="pl-s1">loss</span>.<span class="pl-c1">item</span>())
        <span class="pl-c">#Obtain the mean and variance of the loss value after one iteration.</span>
        <span class="pl-s1">ave_loss</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-c1">average</span>(<span class="pl-s1">losses</span>)
        <span class="pl-s1">var_loss</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-c1">var</span>(<span class="pl-s1">losses</span>)
        <span class="pl-en">print</span>(<span class="pl-s">"μ In Epoch %d: %s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">ave_loss</span>))
        <span class="pl-en">print</span>(<span class="pl-s">"σ In Epoch %d: %s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">var_loss</span>))
        <span class="pl-en">print</span>(<span class="pl-s">"----------------------------------------------------------------"</span>)
        <span class="pl-c">#Record the mean and variance of the loss value.</span>
        <span class="pl-s1">csv_cache</span> <span class="pl-c1">+=</span> <span class="pl-s">"%d,%s,%s<span class="pl-cce">\n</span>"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">ave_loss</span>, <span class="pl-s1">var_loss</span>)
        <span class="pl-c">#Check whether there are checkpoints exceeding the maximum cache count.</span>
        <span class="pl-s1">old_model</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/%s_%d%s"</span> <span class="pl-c1">%</span> (
            <span class="pl-s1">prefix</span>,
            <span class="pl-s1">global_epoch</span> <span class="pl-c1">-</span> <span class="pl-s1">cache_num</span> <span class="pl-c1">*</span> <span class="pl-s1">milestone_step</span>,
            <span class="pl-s1">suffix</span>
        )
        <span class="pl-k">if</span> <span class="pl-s1">os</span>.<span class="pl-c1">path</span>.<span class="pl-c1">exists</span>(<span class="pl-s1">old_model</span>):
            <span class="pl-s1">os</span>.<span class="pl-c1">remove</span>(<span class="pl-s1">old_model</span>)
        <span class="pl-k">if</span> <span class="pl-s1">global_epoch</span> <span class="pl-c1">%</span> <span class="pl-s1">milestone_step</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
            <span class="pl-c">#Save checkpoints.</span>
            <span class="pl-s1">torch</span>.<span class="pl-c1">save</span>(
                <span class="pl-s1">model</span>.<span class="pl-c1">state_dict</span>(),
                <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/%s_%d%s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">prefix</span>, <span class="pl-s1">global_epoch</span>, <span class="pl-s1">suffix</span>)
            )
            <span class="pl-c">#Save loss value information.</span>
            <span class="pl-k">with</span> <span class="pl-en">open</span>(<span class="pl-s1">csv_str</span>, <span class="pl-s">'a'</span>) <span class="pl-k">as</span> <span class="pl-s1">file</span>:
                <span class="pl-s1">file</span>.<span class="pl-c1">write</span>(<span class="pl-s1">csv_cache</span>)
                <span class="pl-s1">csv_cache</span> <span class="pl-c1">=</span> <span class="pl-s">""</span>
            <span class="pl-c">#Perform sampling.</span>
            <span class="pl-c">#This method is described in the following section, Sampling Process.</span>
            <span class="pl-en">milestone_sample</span>(<span class="pl-s1">global_epoch</span>)
        <span class="pl-s1">time</span>.<span class="pl-c1">sleep</span>(<span class="pl-c1">0.1</span>)


<span class="pl-k">def</span> <span class="pl-en">extract</span>(<span class="pl-s1">v</span>, <span class="pl-s1">t</span>, <span class="pl-s1">x_shape</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Used to extract some parameters from the pre-cached noise schedule hyperparameters.</span>
<span class="pl-s">    :param v: Cache, shape [1000]</span>
<span class="pl-s">    :param t: Target timestamp to be extracted, shape [batch_size]</span>
<span class="pl-s">    :param x_shape: Shape of a batch of data, typically [batch_size, channels, image_size, image_size]</span>
<span class="pl-s">    :return: Typically returns a shape of [batch_size, 1, 1, 1]</span>
<span class="pl-s">    """</span>
    <span class="pl-k">return</span> <span class="pl-s1">torch</span>.<span class="pl-c1">gather</span>(<span class="pl-s1">v</span>, <span class="pl-s1">index</span><span class="pl-c1">=</span><span class="pl-s1">t</span>, <span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">0</span>).<span class="pl-c1">float</span>().<span class="pl-c1">cuda</span>().<span class="pl-c1">view</span>([<span class="pl-s1">t</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">0</span>]] <span class="pl-c1">+</span> [<span class="pl-c1">1</span>] <span class="pl-c1">*</span> (<span class="pl-en">len</span>(<span class="pl-s1">x_shape</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>))


<span class="pl-k">def</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">t</span>, <span class="pl-s1">noise</span><span class="pl-c1">=</span><span class="pl-c1">None</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Used to add noise.</span>
<span class="pl-s">    :param x_0:</span>
<span class="pl-s">        Original data used to add noise, with shape [batch_size, channels, image_size, image_size]</span>
<span class="pl-s">    :param t: Specified timestamp, with shape [batch_size]</span>
<span class="pl-s">    :param noise: Specified noise; if None, noise will be randomly generated</span>
<span class="pl-s">    :return: Returns the noisy data at the specified timestamp</span>
<span class="pl-s">    """</span>
    <span class="pl-k">if</span> <span class="pl-s1">noise</span> <span class="pl-c1">is</span> <span class="pl-c1">None</span>:
        <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn_like</span>(<span class="pl-s1">x_0</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#Equation (10)</span>
    <span class="pl-k">return</span> (<span class="pl-en">extract</span>(<span class="pl-s1">sqrt_alphas_bar</span>, <span class="pl-s1">t</span>, <span class="pl-s1">x_0</span>.<span class="pl-c1">shape</span>) <span class="pl-c1">*</span> <span class="pl-s1">x_0</span>
            <span class="pl-c1">+</span> <span class="pl-en">extract</span>(<span class="pl-s1">sqrt_one_minus_alphas_bar</span>, <span class="pl-s1">t</span>, <span class="pl-s1">x_0</span>.<span class="pl-c1">shape</span>) <span class="pl-c1">*</span> <span class="pl-s1">noise</span>)


<span class="pl-k">def</span> <span class="pl-en">get_loss</span>(<span class="pl-s1">x_0</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    To obtain the loss value, the stochastic gradient descent method is used.</span>
<span class="pl-s">    Select any timestamp, calculate the noisy data at that moment, and record the noise used.</span>
<span class="pl-s">    Then, use the noisy data and timestamp as model inputs to obtain the predicted noise.</span>
<span class="pl-s">    Use the recorded noise and predicted noise to calculate the loss value.</span>
<span class="pl-s">    :param x_0: Cache, shape [1000]</span>
<span class="pl-s">    :return: Typically returns a shape of [batch_size, 1, 1, 1]</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">t</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randint</span>(<span class="pl-s1">time_steps</span>, <span class="pl-s1">size</span><span class="pl-c1">=</span>(<span class="pl-s1">batch_size</span>,)).<span class="pl-c1">cuda</span>() <span class="pl-c1">+</span> <span class="pl-c1">1</span>
    <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn_like</span>(<span class="pl-s1">x_0</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-s1">x_t</span> <span class="pl-c1">=</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">t</span>, <span class="pl-s1">noise</span>)
    <span class="pl-c">#Equation (49)</span>
    <span class="pl-k">return</span> <span class="pl-c1">F</span>.<span class="pl-c1">huber_loss</span>(<span class="pl-en">model</span>(<span class="pl-s1">x_t</span>, <span class="pl-s1">t</span>), <span class="pl-s1">noise</span>, <span class="pl-s1">reduction</span><span class="pl-c1">=</span><span class="pl-s">'none'</span>), <span class="pl-s1">t</span></pre></div>
<h2>Sampling Process</h2>
<p>The sampling process is relatively simple, requiring only one iteration. However, for the convenience of subsequent development, it can be written in a modular manner.<br>
The DDPM sampler, i.e., <code class="notranslate">Equation (50)</code>:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-en">@<span class="pl-s1">torch</span>.<span class="pl-c1">no_grad</span>()</span>
<span class="pl-k">def</span> <span class="pl-en">ddpm</span>(<span class="pl-s1">xs</span>, <span class="pl-s1">timestep</span>, <span class="pl-s1">timestep_s</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    :param xs: Corresponding to x_t in equation (50)</span>
<span class="pl-s">    :param timestep: Corresponding to t - 1 in equation (50)</span>
<span class="pl-s">    :param timestep_s: Corresponding to t in equation (50)</span>
<span class="pl-s">    :return: Corresponding to x_{t - 1} in equation (50)</span>
<span class="pl-s">    """</span>
    <span class="pl-c">#α_t = alphas[t - 1]</span>
    <span class="pl-s1">alpha</span> <span class="pl-c1">=</span> <span class="pl-s1">alphas</span>[<span class="pl-s1">timestep</span>]
    <span class="pl-c">#β_t = betas[t - 1]</span>
    <span class="pl-s1">beta</span> <span class="pl-c1">=</span> <span class="pl-s1">betas</span>[<span class="pl-s1">timestep</span>]
    <span class="pl-s1">alpha_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">alphas_bar</span>[<span class="pl-s1">timestep_s</span>]
    <span class="pl-s1">alpha_bar_pre</span> <span class="pl-c1">=</span> <span class="pl-s1">alphas_bar</span>[<span class="pl-s1">timestep</span>]
    <span class="pl-c">#Coefficient before x_t.</span>
    <span class="pl-s1">cof1</span> <span class="pl-c1">=</span> <span class="pl-c1">1</span> <span class="pl-c1">/</span> <span class="pl-s1">alpha</span>.<span class="pl-c1">sqrt</span>()
    <span class="pl-c">#Coefficient before predicted nosie.</span>
    <span class="pl-s1">cof2</span> <span class="pl-c1">=</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha</span>) <span class="pl-c1">/</span> (<span class="pl-s1">alpha</span> <span class="pl-c1">*</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar</span>)).<span class="pl-c1">sqrt</span>()
    <span class="pl-c">#Coefficient before random noise.</span>
    <span class="pl-s1">var</span> <span class="pl-c1">=</span> ((<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar_pre</span>) <span class="pl-c1">/</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar</span>) <span class="pl-c1">*</span> <span class="pl-s1">beta</span>).<span class="pl-c1">sqrt</span>()
    <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">var</span> <span class="pl-c1">*</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span><span class="pl-s1">xs</span>.<span class="pl-c1">shape</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#The shape of t is [1],</span>
    <span class="pl-c">#and its shape is expanded to [batch_size] to be fed into the model for computation.</span>
    <span class="pl-s1">timestep_s</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">full</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span>[<span class="pl-s1">xs</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">0</span>]], <span class="pl-s1">dtype</span><span class="pl-c1">=</span><span class="pl-s1">torch</span>.<span class="pl-c1">long</span>, <span class="pl-s1">fill_value</span><span class="pl-c1">=</span><span class="pl-s1">timestep_s</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#Equation (50)</span>
    <span class="pl-k">return</span> <span class="pl-s1">cof1</span> <span class="pl-c1">*</span> <span class="pl-s1">xs</span> <span class="pl-c1">-</span> <span class="pl-s1">cof2</span> <span class="pl-c1">*</span> <span class="pl-en">model</span>(<span class="pl-s1">xs</span>, <span class="pl-s1">timestep_s</span>) <span class="pl-c1">+</span> <span class="pl-s1">noise</span></pre></div>
<p>Core sampling methods:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">trailing</span>(<span class="pl-s1">steps</span>):
    <span class="pl-k">return</span> <span class="pl-s1">torch</span>.<span class="pl-c1">arange</span>(<span class="pl-s1">time_steps</span>, <span class="pl-c1">0</span>, <span class="pl-c1">-</span><span class="pl-s1">time_steps</span> <span class="pl-c1">/</span> <span class="pl-s1">steps</span>).<span class="pl-c1">flip</span>(<span class="pl-c1">0</span>).<span class="pl-c1">round</span>().<span class="pl-c1">int</span>().<span class="pl-c1">cuda</span>()


<span class="pl-k">def</span> <span class="pl-en">sample</span>(<span class="pl-s1">formats</span>, <span class="pl-s1">configs</span>, <span class="pl-s1">batch</span><span class="pl-c1">=</span><span class="pl-c1">1</span>, <span class="pl-s1">noise</span><span class="pl-c1">=</span><span class="pl-c1">None</span>, <span class="pl-s1">steps</span><span class="pl-c1">=</span><span class="pl-c1">1000</span>,
           <span class="pl-s1">solver</span><span class="pl-c1">=</span><span class="pl-s1">ddpm</span>, <span class="pl-s1">time_schedule</span><span class="pl-c1">=</span><span class="pl-s1">trailing</span>, <span class="pl-s1">desc</span><span class="pl-c1">=</span><span class="pl-s">''</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    :param formats: A list of save formats, input as a method. See the save format method for details.  </span>
<span class="pl-s">    :param configs: Saved configurable settings, input as a dictionary.</span>
<span class="pl-s">        See the default save format for details.</span>
<span class="pl-s">    :param batch: The number of images sampled per batch</span>
<span class="pl-s">    :param noise: Initial noise; if None, random noise will be generated</span>
<span class="pl-s">    :param steps: Number of sampling steps;</span>
<span class="pl-s">        currently, this value can only be 1000. Fast sampling will be introduced in future articles</span>
<span class="pl-s">    :param solver: Sampler; currently, this value can only be ddpm.</span>
<span class="pl-s">        Other samplers will be introduced in future articles</span>
<span class="pl-s">    :param time_schedule: Sampling time series; uses the default trailing</span>
<span class="pl-s">    :param desc: Additional comments that can be displayed in the tqdm progress bar</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span>(<span class="pl-s1">batch</span>, <span class="pl-s1">channels</span>, <span class="pl-s1">image_size</span>, <span class="pl-s1">image_size</span>)).<span class="pl-c1">cuda</span>() \
        <span class="pl-k">if</span> <span class="pl-s1">noise</span> <span class="pl-c1">is</span> <span class="pl-c1">None</span> <span class="pl-k">else</span> <span class="pl-s1">noise</span>
    <span class="pl-s1">img_list</span> <span class="pl-c1">=</span> <span class="pl-en">sample_loop</span>(<span class="pl-s1">noise</span>, <span class="pl-s1">steps</span>, <span class="pl-s1">solver</span>, <span class="pl-s1">time_schedule</span>, <span class="pl-s1">desc</span>)
    <span class="pl-k">for</span> <span class="pl-s1">i</span>, <span class="pl-s1">format_</span> <span class="pl-c1">in</span> <span class="pl-en">enumerate</span>(<span class="pl-s1">formats</span>):
        <span class="pl-en">format_</span>(<span class="pl-s1">img_list</span>, {} <span class="pl-k">if</span> <span class="pl-en">len</span>(<span class="pl-s1">configs</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span> <span class="pl-c1">&lt;</span> <span class="pl-s1">i</span> <span class="pl-c1">or</span> <span class="pl-s1">configs</span>[<span class="pl-s1">i</span>] <span class="pl-c1">is</span> <span class="pl-c1">None</span> <span class="pl-k">else</span> <span class="pl-s1">configs</span>[<span class="pl-s1">i</span>])


<span class="pl-k">def</span> <span class="pl-en">sample_loop</span>(<span class="pl-s1">noise</span>, <span class="pl-s1">steps</span>, <span class="pl-s1">solver</span>, <span class="pl-s1">time_schedule</span>, <span class="pl-s1">extra_desc</span><span class="pl-c1">=</span><span class="pl-s">''</span>):
    <span class="pl-c">#First, a list containing the initial noise will be created.</span>
    <span class="pl-s1">result</span> <span class="pl-c1">=</span> [<span class="pl-s1">noise</span>.<span class="pl-c1">detach</span>().<span class="pl-c1">cpu</span>()]
    <span class="pl-c">#Obtain the sampling timestamp. Based on the current progress, the timestamp is [1, 2, ……, 1000].</span>
    <span class="pl-s1">times_s</span> <span class="pl-c1">=</span> <span class="pl-en">time_schedule</span>(<span class="pl-s1">steps</span>)
    <span class="pl-c">#Obtain the timestamp of the offset, which is [0, 1, ……, 999].</span>
    <span class="pl-s1">times_t</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">cat</span>((<span class="pl-s1">torch</span>.<span class="pl-c1">tensor</span>((<span class="pl-c1">0</span>,)).<span class="pl-c1">cuda</span>(), <span class="pl-s1">times_s</span>[:<span class="pl-c1">-</span><span class="pl-c1">1</span>]))
    <span class="pl-c">#Perform iterative sampling.</span>
    <span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">tqdm</span>(
            <span class="pl-en">reversed</span>(<span class="pl-en">range</span>(<span class="pl-s1">steps</span>)),
            <span class="pl-s1">desc</span><span class="pl-c1">=</span><span class="pl-s">'Now Sampling...'</span> <span class="pl-c1">+</span> <span class="pl-s1">extra_desc</span>,
            <span class="pl-s1">total</span><span class="pl-c1">=</span><span class="pl-s1">steps</span>
    ):
        <span class="pl-c">#Perform a single iteration using the solver.</span>
        <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-en">solver</span>(<span class="pl-s1">noise</span>, <span class="pl-s1">times_t</span>[<span class="pl-s1">i</span>], <span class="pl-s1">times_s</span>[<span class="pl-s1">i</span>])
        <span class="pl-c">#Save intermediate states to a list.</span>
        <span class="pl-s1">result</span>.<span class="pl-c1">append</span>(<span class="pl-s1">noise</span>.<span class="pl-c1">detach</span>().<span class="pl-c1">cpu</span>())
    <span class="pl-c">#Return a list containing all intermediate states.</span>
    <span class="pl-k">return</span> <span class="pl-s1">result</span></pre></div>
<p>For all states obtained from sampling from $t = 1000$ to $t = 0$, define a method for storing the sampling results in a grid format:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-s">"""</span>
<span class="pl-s">All available configurations when the format is set to grid.</span>
<span class="pl-s">saving_folder  : Folder where files are saved</span>
<span class="pl-s">name           : File name for saved files</span>
<span class="pl-s">reverse        : Whether to reverse the grid's length and width</span>
<span class="pl-s">padding_pixels : Spacing between images</span>
<span class="pl-s">"""</span>
<span class="pl-s1">grid_config</span> <span class="pl-c1">=</span> {
    <span class="pl-s">'saving_folder'</span>: <span class="pl-s">'.'</span>,
    <span class="pl-s">'name'</span>: <span class="pl-s">'_grid'</span>,
    <span class="pl-s">'reverse'</span>: <span class="pl-c1">False</span>,
    <span class="pl-s">'padding_pixels'</span>: <span class="pl-c1">2</span>,
}


<span class="pl-k">def</span> <span class="pl-en">grid</span>(<span class="pl-s1">img_list</span>, <span class="pl-s1">config</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Format method variable used for saving.</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">torchvision</span>.<span class="pl-c1">io</span>.<span class="pl-c1">write_png</span>(
        <span class="pl-en">to_grid</span>(<span class="pl-en">to_rgb</span>(<span class="pl-s1">img_list</span>[<span class="pl-c1">-</span><span class="pl-c1">1</span>]), <span class="pl-s1">config</span>),
        <span class="pl-en">get</span>(<span class="pl-s">'saving_folder'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>) <span class="pl-c1">+</span> <span class="pl-s">'/'</span> <span class="pl-c1">+</span> <span class="pl-en">get</span>(<span class="pl-s">'name'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>) <span class="pl-c1">+</span> <span class="pl-s">'.png'</span>
    )


<span class="pl-k">def</span> <span class="pl-en">to_rgb</span>(<span class="pl-s1">tensor</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Converting tensors to image format.</span>
<span class="pl-s">    """</span>
    <span class="pl-k">return</span> ((<span class="pl-s1">tensor</span> <span class="pl-c1">+</span> <span class="pl-s1">torch</span>.<span class="pl-c1">ones_like</span>(<span class="pl-s1">tensor</span>)) <span class="pl-c1">/</span> <span class="pl-c1">2</span> <span class="pl-c1">*</span> <span class="pl-c1">255</span>).<span class="pl-c1">clip</span>(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>)


<span class="pl-k">def</span> <span class="pl-en">closest_divisors</span>(<span class="pl-s1">num</span>: <span class="pl-smi">int</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Used to calculate length and width, making length and width as close as possible.</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">a</span>, <span class="pl-s1">b</span>, <span class="pl-s1">i</span> <span class="pl-c1">=</span> <span class="pl-c1">1</span>, <span class="pl-s1">num</span>, <span class="pl-c1">0</span>
    <span class="pl-k">while</span> <span class="pl-s1">a</span> <span class="pl-c1">&lt;</span> <span class="pl-s1">b</span>:
        <span class="pl-s1">i</span> <span class="pl-c1">+=</span> <span class="pl-c1">1</span>
        <span class="pl-k">if</span> <span class="pl-s1">num</span> <span class="pl-c1">%</span> <span class="pl-s1">i</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
            <span class="pl-s1">a</span> <span class="pl-c1">=</span> <span class="pl-s1">i</span>
            <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">num</span> <span class="pl-c1">//</span> <span class="pl-s1">a</span>
    <span class="pl-k">return</span> [<span class="pl-s1">b</span>, <span class="pl-s1">a</span>]


<span class="pl-k">def</span> <span class="pl-en">to_pixel_coord</span>(<span class="pl-s1">num</span>, <span class="pl-s1">padding_pixels</span>: <span class="pl-smi">int</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Used to calculate pixel coordinates for creating grids.</span>
<span class="pl-s">    """</span>
    <span class="pl-k">return</span> <span class="pl-s1">num</span> <span class="pl-c1">*</span> <span class="pl-s1">image_size</span> <span class="pl-c1">+</span> (<span class="pl-s1">num</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>) <span class="pl-c1">*</span> <span class="pl-s1">padding_pixels</span>


<span class="pl-k">def</span> <span class="pl-en">to_grid</span>(<span class="pl-s1">imgs</span>, <span class="pl-s1">config</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Convert a batch of image tensors into a single grid tensor form.</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">batch</span> <span class="pl-c1">=</span> <span class="pl-s1">imgs</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">0</span>]
    <span class="pl-s1">x</span>, <span class="pl-s1">y</span> <span class="pl-c1">=</span> <span class="pl-en">closest_divisors</span>(<span class="pl-s1">batch</span>)
    <span class="pl-k">if</span> <span class="pl-en">get</span>(<span class="pl-s">'reverse'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>):
        <span class="pl-s1">x</span>, <span class="pl-s1">y</span> <span class="pl-c1">=</span> <span class="pl-s1">y</span>, <span class="pl-s1">x</span>
    <span class="pl-s1">px</span> <span class="pl-c1">=</span> <span class="pl-en">get</span>(<span class="pl-s">'padding_pixels'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>)
    <span class="pl-s1">width</span> <span class="pl-c1">=</span> <span class="pl-en">to_pixel_coord</span>(<span class="pl-s1">x</span>, <span class="pl-s1">px</span>)
    <span class="pl-s1">height</span> <span class="pl-c1">=</span> <span class="pl-en">to_pixel_coord</span>(<span class="pl-s1">y</span>, <span class="pl-s1">px</span>)
    <span class="pl-s1">result</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">full</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span>(<span class="pl-s1">imgs</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">1</span>], <span class="pl-s1">height</span>, <span class="pl-s1">width</span>), <span class="pl-s1">fill_value</span><span class="pl-c1">=</span><span class="pl-c1">1.</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>)
    <span class="pl-k">for</span> <span class="pl-s1">j</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">batch</span>):
        <span class="pl-s1">h_coord</span> <span class="pl-c1">=</span> <span class="pl-s1">j</span> <span class="pl-c1">//</span> <span class="pl-s1">x</span> <span class="pl-c1">*</span> (<span class="pl-s1">image_size</span> <span class="pl-c1">+</span> <span class="pl-s1">px</span>) <span class="pl-c1">+</span> <span class="pl-s1">px</span>
        <span class="pl-s1">w_coord</span> <span class="pl-c1">=</span> <span class="pl-s1">j</span> <span class="pl-c1">%</span> <span class="pl-s1">x</span> <span class="pl-c1">*</span> (<span class="pl-s1">image_size</span> <span class="pl-c1">+</span> <span class="pl-s1">px</span>) <span class="pl-c1">+</span> <span class="pl-s1">px</span>
        <span class="pl-s1">result</span>[:, <span class="pl-s1">h_coord</span>:<span class="pl-s1">h_coord</span> <span class="pl-c1">+</span> <span class="pl-s1">image_size</span>, <span class="pl-s1">w_coord</span>: <span class="pl-s1">w_coord</span> <span class="pl-c1">+</span> <span class="pl-s1">image_size</span>] <span class="pl-c1">=</span> <span class="pl-s1">imgs</span>[<span class="pl-s1">j</span>]
    <span class="pl-k">return</span> <span class="pl-s1">result</span>


<span class="pl-k">def</span> <span class="pl-en">get</span>(<span class="pl-s1">par</span>, <span class="pl-s1">config</span>, <span class="pl-s1">config_</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    Obtain configurable parameter values.</span>
<span class="pl-s">    """</span>
    <span class="pl-k">try</span>:
        <span class="pl-k">return</span> <span class="pl-s1">config</span>[<span class="pl-s1">par</span>]
    <span class="pl-k">except</span>:
        <span class="pl-k">return</span> <span class="pl-s1">config_</span>[<span class="pl-s1">par</span>]</pre></div>
<p>Then, you can complete the milestone_sample method mentioned in the training process:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">milestone_sample</span>(<span class="pl-s1">global_epoch</span>, <span class="pl-s1">solver</span><span class="pl-c1">=</span><span class="pl-s1">ddpm</span>):
    <span class="pl-s1">milestone_path</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/milestone"</span>
    <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">os</span>.<span class="pl-c1">path</span>.<span class="pl-c1">exists</span>(<span class="pl-s1">milestone_path</span>):
        <span class="pl-s1">os</span>.<span class="pl-c1">mkdir</span>(<span class="pl-s1">milestone_path</span>)
    <span class="pl-en">print</span>(<span class="pl-s">"Now Sampling Milestone"</span>)
    <span class="pl-s1">time</span>.<span class="pl-c1">sleep</span>(<span class="pl-c1">0.1</span>)
    <span class="pl-c">#Call the sampling core method, use grid as the storage format,</span>
    <span class="pl-c">#save the results to the milestone folder, and sample 16 images at a time.</span>
    <span class="pl-en">sample</span>(
        <span class="pl-s1">formats</span><span class="pl-c1">=</span>[<span class="pl-s1">grid</span>],
        <span class="pl-s1">configs</span><span class="pl-c1">=</span>[{
            <span class="pl-s">'saving_folder'</span>: <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/milestone"</span>,
            <span class="pl-s">'name'</span>: <span class="pl-s">'epoch_%d'</span> <span class="pl-c1">%</span> <span class="pl-s1">global_epoch</span>
        }],
        <span class="pl-s1">batch</span><span class="pl-c1">=</span><span class="pl-c1">16</span>,
        <span class="pl-s1">solver</span><span class="pl-c1">=</span><span class="pl-s1">solver</span>
    )
    <span class="pl-en">print</span>(<span class="pl-s">"----------------------------------------------------------------"</span>)</pre></div>
<h2>Code Execution</h2>
<p>This completes the code implementation of DDPM, and training can now begin:</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">if</span> <span class="pl-s1">__name__</span> <span class="pl-c1">==</span> <span class="pl-s">'__main__'</span>:
    <span class="pl-en">train</span>()</pre></div>
<p>The first 100 iterations of training process:</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/cifar1_10_100.png"/></p></p>
<p>The 500 iterations of the training process:</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/cifar1_50_500.png"/></p></p>
<p>Changes in training loss values:</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/cifar1_loss.png" width="400" height="300"/></p></p>
<h2>Summary</h2>
<p>At this point, we have completed the reproduction of the DDPM algorithm. If you have run the code yourself, you will undoubtedly have felt the significant computational power requirements of diffusion models, which has inspired subsequent research into fast sampling.</p>
<p>Due to <code class="notranslate">The limitations of the blog framework</code>, there is still a lot of content that has not been fully explained. I will try to supplement and explain some of the more difficult concepts in future posts, or perhaps write a separate article to explain them in more detail.;;;e;;;c</p>
<h2>训练过程</h2>
<p>首先导入一些必要的库：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">import</span> <span class="pl-s1">time</span>
<span class="pl-k">from</span> <span class="pl-s1">pathlib</span> <span class="pl-k">import</span> <span class="pl-v">Path</span>

<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>
<span class="pl-k">import</span> <span class="pl-s1">torch</span>.<span class="pl-s1">nn</span>.<span class="pl-s1">functional</span> <span class="pl-k">as</span> <span class="pl-c1">F</span>
<span class="pl-k">import</span> <span class="pl-s1">torchvision</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span> <span class="pl-k">import</span> <span class="pl-s1">optim</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span>.<span class="pl-s1">utils</span>.<span class="pl-s1">data</span> <span class="pl-k">import</span> <span class="pl-v">DataLoader</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span> <span class="pl-k">import</span> <span class="pl-s1">datasets</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">transforms</span>.<span class="pl-s1">v2</span> <span class="pl-k">import</span> <span class="pl-v">Lambda</span>, <span class="pl-v">ToTensor</span>, <span class="pl-v">RandomHorizontalFlip</span>, <span class="pl-v">Compose</span>, <span class="pl-v">Grayscale</span>
<span class="pl-k">from</span> <span class="pl-s1">tqdm</span> <span class="pl-k">import</span> <span class="pl-s1">tqdm</span>

<span class="pl-k">import</span> <span class="pl-s1">unet</span></pre></div>
<p>其次是一些训练配置、超参数的确定。对于$\beta_t$等超参数，<code class="notranslate">选择线性噪声时间表</code>：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">linear</span>(<span class="pl-s1">time_steps</span>):
    <span class="pl-s1">beta_start</span> <span class="pl-c1">=</span> <span class="pl-c1">0.0001</span>
    <span class="pl-s1">beta_end</span> <span class="pl-c1">=</span> <span class="pl-c1">0.02</span>
    <span class="pl-k">return</span> <span class="pl-s1">torch</span>.<span class="pl-c1">linspace</span>(<span class="pl-s1">beta_start</span>, <span class="pl-s1">beta_end</span>, <span class="pl-s1">time_steps</span>).<span class="pl-c1">cuda</span>()


<span class="pl-c">#时间戳选定为从0到1000，若减少或增加该值，会改变噪声时间表相关参数</span>
<span class="pl-s1">time_steps</span> <span class="pl-c1">=</span> <span class="pl-c1">1000</span>
<span class="pl-c">#噪声时间表相关参数的预先计算缓存</span>
<span class="pl-c">#形状：[1000]</span>
<span class="pl-s1">betas</span> <span class="pl-c1">=</span> <span class="pl-en">linear</span>(<span class="pl-s1">time_steps</span>)
<span class="pl-c">#形状：[1000]</span>
<span class="pl-s1">alphas</span> <span class="pl-c1">=</span> <span class="pl-c1">1.</span> <span class="pl-c1">-</span> <span class="pl-s1">betas</span>
<span class="pl-c">#形状：[1001]</span>
<span class="pl-s1">alphas_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">cat</span>((<span class="pl-s1">torch</span>.<span class="pl-c1">tensor</span>((<span class="pl-c1">1</span>,)).<span class="pl-c1">cuda</span>(), <span class="pl-s1">torch</span>.<span class="pl-c1">cumprod</span>(<span class="pl-s1">input</span><span class="pl-c1">=</span><span class="pl-s1">alphas</span>, <span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">0</span>)))
<span class="pl-c">#形状：[1001]</span>
<span class="pl-s1">sqrt_alphas_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">sqrt</span>(<span class="pl-s1">alphas_bar</span>)
<span class="pl-c">#形状：[1001]</span>
<span class="pl-s1">sqrt_one_minus_alphas_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">sqrt</span>(<span class="pl-c1">1.</span> <span class="pl-c1">-</span> <span class="pl-s1">alphas_bar</span>)</pre></div>
<p>配置与超参数：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-s">"""</span>
<span class="pl-s">为简便演示，使用CIFAR1作为数据集，图片尺寸为32×32</span>
<span class="pl-s">CIFAR1指仅仅选用CIFAR10中的一类作为数据集</span>
<span class="pl-s">数据集的文件结构为</span>
<span class="pl-s">cifar1</span>
<span class="pl-s">├── test</span>
<span class="pl-s">│   └── horse</span>
<span class="pl-s">│       ├── 0001.png</span>
<span class="pl-s">│       ├── 0002.png</span>
<span class="pl-s">│       ├── ...</span>
<span class="pl-s">│       └── 5000.png</span>
<span class="pl-s">└── train</span>
<span class="pl-s">    └── horse</span>
<span class="pl-s">        ├── 0001.png</span>
<span class="pl-s">        ├── 0002.png</span>
<span class="pl-s">        ├── ...</span>
<span class="pl-s">        └── 1000.png</span>
<span class="pl-s">"""</span>
<span class="pl-s1">image_size</span> <span class="pl-c1">=</span> <span class="pl-c1">32</span>
<span class="pl-c">#通道数为3，即RGB</span>
<span class="pl-s1">channels</span> <span class="pl-c1">=</span> <span class="pl-c1">3</span>
<span class="pl-c">#模型的基础通道数，即最上层的通道数</span>
<span class="pl-s1">base_channels</span> <span class="pl-c1">=</span> <span class="pl-c1">128</span>
<span class="pl-c">#模型的不同层的通道数，分辨率为32×32时，模型的深度选则4，对应的通道数为128，256，256，256</span>
<span class="pl-s1">ch_mults</span> <span class="pl-c1">=</span> {
    <span class="pl-c1">32</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>),
    <span class="pl-c1">64</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>),
    <span class="pl-c1">128</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>),
    <span class="pl-c1">256</span>: (<span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">4</span>, <span class="pl-c1">4</span>),
    <span class="pl-c1">512</span>: (<span class="pl-c1">0.5</span>, <span class="pl-c1">1</span>, <span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">2</span>, <span class="pl-c1">4</span>, <span class="pl-c1">4</span>)
}
<span class="pl-c">#学习率</span>
<span class="pl-s1">learning_rate</span> <span class="pl-c1">=</span> <span class="pl-c1">1e-4</span>
<span class="pl-c">#训练轮数，选定迭代数据集500次（实际上该轮数是远远不够的）</span>
<span class="pl-s1">epochs</span> <span class="pl-c1">=</span> <span class="pl-c1">500</span>
<span class="pl-c">#每多少轮数进行以此采样以及模型的检查点保存</span>
<span class="pl-s1">milestone_step</span> <span class="pl-c1">=</span> <span class="pl-c1">10</span>
<span class="pl-c">#检查点保存的最大数量</span>
<span class="pl-s1">cache_num</span> <span class="pl-c1">=</span> <span class="pl-c1">10</span>
<span class="pl-c">#一个批次训练图片的数量，在该案例下，128张适合拥有8G显存的显卡</span>
<span class="pl-s1">batch_size</span> <span class="pl-c1">=</span> <span class="pl-c1">128</span>
<span class="pl-c">#checkpoints的拟定位置</span>
<span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">=</span> <span class="pl-s">'cifar1/cp'</span>
<span class="pl-c">#训练集的位置</span>
<span class="pl-s1">datasets_folder</span> <span class="pl-c1">=</span> <span class="pl-s">'cifar1/train'</span>
<span class="pl-c">#用以收集训练时损失值的文件</span>
<span class="pl-s1">csv_str</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">'/loss.csv'</span>
<span class="pl-c">#模型检查点保存文件名的前缀</span>
<span class="pl-s1">prefix</span> <span class="pl-c1">=</span> <span class="pl-s">"checkpoint_epoch"</span>
<span class="pl-c">#模型检查点保存文件名的后缀</span>
<span class="pl-s1">suffix</span> <span class="pl-c1">=</span> <span class="pl-s">".pth"</span>
<span class="pl-c">#为checkpoints新建文件夹</span>
<span class="pl-en">Path</span>(<span class="pl-s1">checkpoint_folder</span>).<span class="pl-c1">mkdir</span>(<span class="pl-s1">exist_ok</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
<span class="pl-en">Path</span>(<span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">'/milestone'</span>).<span class="pl-c1">mkdir</span>(<span class="pl-s1">exist_ok</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
<span class="pl-c">#新建模型</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">unet</span>.<span class="pl-c1">UNetModel</span>(
    <span class="pl-s1">image_size</span><span class="pl-c1">=</span><span class="pl-s1">image_size</span>,
    <span class="pl-s1">in_channels</span><span class="pl-c1">=</span><span class="pl-s1">channels</span>,
    <span class="pl-s1">model_channels</span><span class="pl-c1">=</span><span class="pl-s1">base_channels</span>,
    <span class="pl-s1">out_channels</span><span class="pl-c1">=</span><span class="pl-s1">channels</span>,
    <span class="pl-s1">num_res_blocks</span><span class="pl-c1">=</span><span class="pl-c1">2</span>,
    <span class="pl-s1">attention_resolutions</span><span class="pl-c1">=</span>(<span class="pl-c1">32</span>, <span class="pl-c1">16</span>, <span class="pl-c1">8</span>),
    <span class="pl-s1">dropout</span><span class="pl-c1">=</span><span class="pl-c1">0.0</span>,
    <span class="pl-s1">channel_mult</span><span class="pl-c1">=</span><span class="pl-s1">ch_mults</span>[<span class="pl-s1">image_size</span>],
    <span class="pl-s1">num_heads</span><span class="pl-c1">=</span><span class="pl-c1">4</span>,
    <span class="pl-s1">num_head_channels</span><span class="pl-c1">=</span><span class="pl-c1">-</span><span class="pl-c1">1</span>,
)
<span class="pl-c">#若checkpoints文件夹内存在模型检查点，则读取最新的检查点</span>
<span class="pl-s1">last_model</span> <span class="pl-c1">=</span> <span class="pl-c1">None</span>
<span class="pl-s1">last</span> <span class="pl-c1">=</span> <span class="pl-c1">0</span>
<span class="pl-k">for</span> <span class="pl-s1">file</span> <span class="pl-c1">in</span> <span class="pl-s1">os</span>.<span class="pl-c1">listdir</span>(<span class="pl-s1">checkpoint_folder</span>):
    <span class="pl-k">if</span> <span class="pl-s1">file</span>[:<span class="pl-en">len</span>(<span class="pl-s1">prefix</span>)] <span class="pl-c1">!=</span> <span class="pl-s1">prefix</span>:
        <span class="pl-k">continue</span>
    <span class="pl-s1">epochs_str</span> <span class="pl-c1">=</span> <span class="pl-s1">file</span>[<span class="pl-en">len</span>(<span class="pl-s1">prefix</span>) <span class="pl-c1">+</span> <span class="pl-c1">1</span>:<span class="pl-c1">0</span> <span class="pl-c1">-</span> <span class="pl-en">len</span>(<span class="pl-s1">suffix</span>)]
    <span class="pl-k">if</span> <span class="pl-en">int</span>(<span class="pl-s1">epochs_str</span>) <span class="pl-c1">&gt;</span> <span class="pl-s1">last</span>:
        <span class="pl-s1">last</span> <span class="pl-c1">=</span> <span class="pl-en">int</span>(<span class="pl-s1">epochs_str</span>)
<span class="pl-k">if</span> <span class="pl-s1">last</span> <span class="pl-c1">&gt;</span> <span class="pl-c1">0</span>:
    <span class="pl-s1">last_model</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">load</span>(<span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/%s_%d%s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">prefix</span>, <span class="pl-s1">last</span>, <span class="pl-s1">suffix</span>), <span class="pl-s1">weights_only</span><span class="pl-c1">=</span><span class="pl-c1">False</span>)
<span class="pl-k">if</span> <span class="pl-s1">last_model</span> <span class="pl-c1"><span class="pl-c1">is</span> <span class="pl-c1">not</span></span> <span class="pl-c1">None</span>:
    <span class="pl-s1">model</span>.<span class="pl-c1">load_state_dict</span>(<span class="pl-s1">last_model</span>)
<span class="pl-k">else</span>:
    <span class="pl-en">print</span>(<span class="pl-s">"No Checkpoints Exist"</span>)
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-c1">cuda</span>()
<span class="pl-c">#统计模型的参数数量</span>
<span class="pl-s1">parameters</span> <span class="pl-c1">=</span> <span class="pl-en">sum</span>(<span class="pl-s1">p</span>.<span class="pl-c1">numel</span>() <span class="pl-k">for</span> <span class="pl-s1">p</span> <span class="pl-c1">in</span> <span class="pl-s1">model</span>.<span class="pl-c1">parameters</span>() <span class="pl-k">if</span> <span class="pl-s1">p</span>.<span class="pl-c1">requires_grad</span>)
<span class="pl-s1">count_str</span> <span class="pl-c1">=</span> <span class="pl-s">"Parameters Count: "</span>
<span class="pl-en">print</span>(<span class="pl-s1">count_str</span> <span class="pl-c1">+</span> <span class="pl-s">"%.2fB"</span> <span class="pl-c1">%</span> (<span class="pl-s1">parameters</span> <span class="pl-c1">/</span> <span class="pl-c1">1e9</span>)) \
    <span class="pl-k">if</span> <span class="pl-s1">parameters</span> <span class="pl-c1">&gt;</span> <span class="pl-c1">1e9</span> <span class="pl-k">else</span> <span class="pl-en">print</span>(<span class="pl-s1">count_str</span> <span class="pl-c1">+</span> <span class="pl-s">"%.2fM"</span> <span class="pl-c1">%</span> (<span class="pl-s1">parameters</span> <span class="pl-c1">/</span> <span class="pl-c1">1e6</span>))
<span class="pl-c">#优化器</span>
<span class="pl-s1">optimizer</span> <span class="pl-c1">=</span> <span class="pl-s1">optim</span>.<span class="pl-c1">AdamW</span>(<span class="pl-s1">model</span>.<span class="pl-c1">parameters</span>(), <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-s1">learning_rate</span>, <span class="pl-s1">weight_decay</span><span class="pl-c1">=</span><span class="pl-c1">1e-4</span>)
<span class="pl-c">#将图片转化为张量</span>
<span class="pl-s">"""</span>
<span class="pl-s">ToTensor()                    :读取图片，并将其从[0, 255]的整数缩放为[0, 1]的浮点数</span>
<span class="pl-s">Lambda(lambda t: (t * 2) - 1) :将[0, 1]的浮点数缩放为[-1, 1]的浮点数</span>
<span class="pl-s">RandomHorizontalFlip()        :对数据进行随机的水平方向的翻转</span>
<span class="pl-s">"""</span>
<span class="pl-s1">transform</span> <span class="pl-c1">=</span> <span class="pl-en">Compose</span>(
    [<span class="pl-en">Grayscale</span>(), <span class="pl-en">ToTensor</span>(), <span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">*</span> <span class="pl-c1">2</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>), <span class="pl-en">RandomHorizontalFlip</span>()]
    <span class="pl-k">if</span> <span class="pl-s1">channels</span> <span class="pl-c1">==</span> <span class="pl-c1">1</span> <span class="pl-k">else</span>
    [<span class="pl-en">ToTensor</span>(), <span class="pl-en">Lambda</span>(<span class="pl-k">lambda</span> <span class="pl-s1">t</span>: (<span class="pl-s1">t</span> <span class="pl-c1">*</span> <span class="pl-c1">2</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>), <span class="pl-en">RandomHorizontalFlip</span>()]
)</pre></div>
<p>训练的核心方法：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">train</span>():
    <span class="pl-en">train_loop</span>(<span class="pl-en">DataLoader</span>(
        <span class="pl-s1">datasets</span>.<span class="pl-c1">ImageFolder</span>(<span class="pl-s1">datasets_folder</span>, <span class="pl-s1">transform</span><span class="pl-c1">=</span><span class="pl-s1">transform</span>),
        <span class="pl-s1">batch_size</span><span class="pl-c1">=</span><span class="pl-s1">batch_size</span>,
        <span class="pl-s1">shuffle</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
        <span class="pl-s1">drop_last</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
        <span class="pl-s1">pin_memory</span><span class="pl-c1">=</span><span class="pl-c1">True</span>
    ))


<span class="pl-k">def</span> <span class="pl-en">train_loop</span>(<span class="pl-s1">dataloader</span>):
    <span class="pl-c">#计算剩余需要迭代的次数</span>
    <span class="pl-s1">local_epochs</span> <span class="pl-c1">=</span> <span class="pl-s1">epochs</span> <span class="pl-c1">-</span> <span class="pl-s1">last</span>
    <span class="pl-c">#损失值文件的写入缓存</span>
    <span class="pl-s1">csv_cache</span> <span class="pl-c1">=</span> <span class="pl-s">""</span>
    <span class="pl-en">print</span>()
    <span class="pl-en">print</span>(<span class="pl-s">"Now Strat Training"</span>)
    <span class="pl-k">for</span> <span class="pl-s1">epoch</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">local_epochs</span>):
        <span class="pl-c">#损失值的缓存</span>
        <span class="pl-s1">losses</span> <span class="pl-c1">=</span> []
        <span class="pl-c">#若不等待，貌似tqdm的进度条会出现一些问题？</span>
        <span class="pl-s1">time</span>.<span class="pl-c1">sleep</span>(<span class="pl-c1">0.1</span>)
        <span class="pl-c">#计算当前的迭代次数</span>
        <span class="pl-s1">global_epoch</span> <span class="pl-c1">=</span> <span class="pl-s1">epoch</span> <span class="pl-c1">+</span> <span class="pl-s1">last</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>
        <span class="pl-c">#对数据集进行遍历</span>
        <span class="pl-k">for</span> <span class="pl-s1">step</span>, <span class="pl-s1">data_batch</span> <span class="pl-c1">in</span> (<span class="pl-s1">pbar</span> <span class="pl-c1">:=</span> <span class="pl-en">tqdm</span>(
                <span class="pl-en">enumerate</span>(<span class="pl-s1">dataloader</span>),
                <span class="pl-s1">total</span><span class="pl-c1">=</span><span class="pl-en">len</span>(<span class="pl-s1">dataloader</span>),
                <span class="pl-s1">desc</span><span class="pl-c1">=</span><span class="pl-s">"Epoch: %d/ %d With Loss %f"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">epochs</span>, <span class="pl-c1">1</span>)
        )):
            <span class="pl-c">#初始化优化器</span>
            <span class="pl-s1">optimizer</span>.<span class="pl-c1">zero_grad</span>()
            <span class="pl-c">#获取该批次的全部数据张量，其形状为[batch_size, channels, image_size, image_size]</span>
            <span class="pl-s1">data_batch</span> <span class="pl-c1">=</span> <span class="pl-s1">data_batch</span>[<span class="pl-c1">0</span>].<span class="pl-c1">cuda</span>()
            <span class="pl-c">#获取损失值以及计算损失值所随机到的时间戳</span>
            <span class="pl-s1">complex_loss</span>, <span class="pl-s1">t</span> <span class="pl-c1">=</span> <span class="pl-en">get_loss</span>(<span class="pl-s1">data_batch</span>)
            <span class="pl-s1">loss</span> <span class="pl-c1">=</span> <span class="pl-s1">complex_loss</span>.<span class="pl-c1">sum</span>() <span class="pl-c1">/</span> <span class="pl-c1">1000.</span>
            <span class="pl-s1">loss</span>.<span class="pl-c1">backward</span>()
            <span class="pl-s1">torch</span>.<span class="pl-c1">nn</span>.<span class="pl-c1">utils</span>.<span class="pl-c1">clip_grad_norm_</span>(<span class="pl-s1">model</span>.<span class="pl-c1">parameters</span>(), <span class="pl-c1">1.</span>)
            <span class="pl-s1">optimizer</span>.<span class="pl-c1">step</span>()
            <span class="pl-s1">pbar</span>.<span class="pl-c1">set_description</span>(<span class="pl-s">"Epoch: %d/ %d With Loss %f "</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">epochs</span>, <span class="pl-s1">loss</span>.<span class="pl-c1">item</span>()))
            <span class="pl-c">#记录该批次的损失值</span>
            <span class="pl-s1">losses</span>.<span class="pl-c1">append</span>(<span class="pl-s1">loss</span>.<span class="pl-c1">item</span>())
        <span class="pl-c">#获取一轮迭代后的损失值的平均值及方差</span>
        <span class="pl-s1">ave_loss</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-c1">average</span>(<span class="pl-s1">losses</span>)
        <span class="pl-s1">var_loss</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-c1">var</span>(<span class="pl-s1">losses</span>)
        <span class="pl-en">print</span>(<span class="pl-s">"μ In Epoch %d: %s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">ave_loss</span>))
        <span class="pl-en">print</span>(<span class="pl-s">"σ In Epoch %d: %s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">var_loss</span>))
        <span class="pl-en">print</span>(<span class="pl-s">"----------------------------------------------------------------"</span>)
        <span class="pl-c">#记录损失值的平均值及方差</span>
        <span class="pl-s1">csv_cache</span> <span class="pl-c1">+=</span> <span class="pl-s">"%d,%s,%s<span class="pl-cce">\n</span>"</span> <span class="pl-c1">%</span> (<span class="pl-s1">global_epoch</span>, <span class="pl-s1">ave_loss</span>, <span class="pl-s1">var_loss</span>)
        <span class="pl-c">#检查是否存在超出最大缓存数量的检查点</span>
        <span class="pl-s1">old_model</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/%s_%d%s"</span> <span class="pl-c1">%</span> (
            <span class="pl-s1">prefix</span>,
            <span class="pl-s1">global_epoch</span> <span class="pl-c1">-</span> <span class="pl-s1">cache_num</span> <span class="pl-c1">*</span> <span class="pl-s1">milestone_step</span>,
            <span class="pl-s1">suffix</span>
        )
        <span class="pl-k">if</span> <span class="pl-s1">os</span>.<span class="pl-c1">path</span>.<span class="pl-c1">exists</span>(<span class="pl-s1">old_model</span>):
            <span class="pl-s1">os</span>.<span class="pl-c1">remove</span>(<span class="pl-s1">old_model</span>)
        <span class="pl-k">if</span> <span class="pl-s1">global_epoch</span> <span class="pl-c1">%</span> <span class="pl-s1">milestone_step</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
            <span class="pl-c">#保存检查点</span>
            <span class="pl-s1">torch</span>.<span class="pl-c1">save</span>(
                <span class="pl-s1">model</span>.<span class="pl-c1">state_dict</span>(),
                <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/%s_%d%s"</span> <span class="pl-c1">%</span> (<span class="pl-s1">prefix</span>, <span class="pl-s1">global_epoch</span>, <span class="pl-s1">suffix</span>)
            )
            <span class="pl-c">#保存损失值信息</span>
            <span class="pl-k">with</span> <span class="pl-en">open</span>(<span class="pl-s1">csv_str</span>, <span class="pl-s">'a'</span>) <span class="pl-k">as</span> <span class="pl-s1">file</span>:
                <span class="pl-s1">file</span>.<span class="pl-c1">write</span>(<span class="pl-s1">csv_cache</span>)
                <span class="pl-s1">csv_cache</span> <span class="pl-c1">=</span> <span class="pl-s">""</span>
            <span class="pl-c">#进行一次采样，该方法在接下来的章节——采样过程中给出</span>
            <span class="pl-en">milestone_sample</span>(<span class="pl-s1">global_epoch</span>)
        <span class="pl-s1">time</span>.<span class="pl-c1">sleep</span>(<span class="pl-c1">0.1</span>)


<span class="pl-k">def</span> <span class="pl-en">extract</span>(<span class="pl-s1">v</span>, <span class="pl-s1">t</span>, <span class="pl-s1">x_shape</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    用于将一些参数从噪声时间表超参数的预先缓存中提取出来。</span>
<span class="pl-s">    :param v:缓存，形状为[1000]</span>
<span class="pl-s">    :param t:需要提取的目标时间戳，形状为[batch_size]</span>
<span class="pl-s">    :param x_shape:一个批次数据的形状，一般为[batch_size, channels, image_size, image_size]</span>
<span class="pl-s">    :return:一般返回的形状为[batch_size, 1, 1, 1]</span>
<span class="pl-s">    """</span>
    <span class="pl-k">return</span> <span class="pl-s1">torch</span>.<span class="pl-c1">gather</span>(<span class="pl-s1">v</span>, <span class="pl-s1">index</span><span class="pl-c1">=</span><span class="pl-s1">t</span>, <span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">0</span>).<span class="pl-c1">float</span>().<span class="pl-c1">cuda</span>().<span class="pl-c1">view</span>([<span class="pl-s1">t</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">0</span>]] <span class="pl-c1">+</span> [<span class="pl-c1">1</span>] <span class="pl-c1">*</span> (<span class="pl-en">len</span>(<span class="pl-s1">x_shape</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>))


<span class="pl-k">def</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">t</span>, <span class="pl-s1">noise</span><span class="pl-c1">=</span><span class="pl-c1">None</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    用于添加噪声。</span>
<span class="pl-s">    :param x_0:用于添加噪声的原始数据，形状为[batch_size, channels, image_size, image_size]</span>
<span class="pl-s">    :param t:指定的时间戳，形状为[batch_size]</span>
<span class="pl-s">    :param noise:指定的噪声，若为None，则会随机生成噪声</span>
<span class="pl-s">    :return:返回指定时间戳下的带噪数据</span>
<span class="pl-s">    """</span>
    <span class="pl-k">if</span> <span class="pl-s1">noise</span> <span class="pl-c1">is</span> <span class="pl-c1">None</span>:
        <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn_like</span>(<span class="pl-s1">x_0</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#式(10)</span>
    <span class="pl-k">return</span> (<span class="pl-en">extract</span>(<span class="pl-s1">sqrt_alphas_bar</span>, <span class="pl-s1">t</span>, <span class="pl-s1">x_0</span>.<span class="pl-c1">shape</span>) <span class="pl-c1">*</span> <span class="pl-s1">x_0</span>
            <span class="pl-c1">+</span> <span class="pl-en">extract</span>(<span class="pl-s1">sqrt_one_minus_alphas_bar</span>, <span class="pl-s1">t</span>, <span class="pl-s1">x_0</span>.<span class="pl-c1">shape</span>) <span class="pl-c1">*</span> <span class="pl-s1">noise</span>)


<span class="pl-k">def</span> <span class="pl-en">get_loss</span>(<span class="pl-s1">x_0</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    用于获取损失值，采用随机梯度下降法。</span>
<span class="pl-s">    选取任意的时间戳，计算该时刻的带噪数据，并记录所使用的噪声，</span>
<span class="pl-s">    再将带噪数据与时间戳作为模型输入，得到预测的噪声，</span>
<span class="pl-s">    使用记录的噪声与预测的噪声来计算损失值。</span>
<span class="pl-s">    :param x_0:缓存，形状为[1000]</span>
<span class="pl-s">    :return:一般返回的形状为[batch_size, 1, 1, 1]</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">t</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randint</span>(<span class="pl-s1">time_steps</span>, <span class="pl-s1">size</span><span class="pl-c1">=</span>(<span class="pl-s1">batch_size</span>,)).<span class="pl-c1">cuda</span>() <span class="pl-c1">+</span> <span class="pl-c1">1</span>
    <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn_like</span>(<span class="pl-s1">x_0</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-s1">x_t</span> <span class="pl-c1">=</span> <span class="pl-en">add_noise</span>(<span class="pl-s1">x_0</span>, <span class="pl-s1">t</span>, <span class="pl-s1">noise</span>)
    <span class="pl-c">#式(49)</span>
    <span class="pl-k">return</span> <span class="pl-c1">F</span>.<span class="pl-c1">huber_loss</span>(<span class="pl-en">model</span>(<span class="pl-s1">x_t</span>, <span class="pl-s1">t</span>), <span class="pl-s1">noise</span>, <span class="pl-s1">reduction</span><span class="pl-c1">=</span><span class="pl-s">'none'</span>), <span class="pl-s1">t</span></pre></div>
<h2>采样过程</h2>
<p>采样过程相较而言就简单很多，只需要进行一个迭代即可。但为方便后续开发，可以对其进行模块化编写。<br>
DDPM的采样器，即<code class="notranslate">式(50)</code>：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-en">@<span class="pl-s1">torch</span>.<span class="pl-c1">no_grad</span>()</span>
<span class="pl-k">def</span> <span class="pl-en">ddpm</span>(<span class="pl-s1">xs</span>, <span class="pl-s1">timestep</span>, <span class="pl-s1">timestep_s</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    :param xs:对应式(50)中的x_t</span>
<span class="pl-s">    :param timestep:对应式(50)中的t - 1</span>
<span class="pl-s">    :param timestep_s:对应式(50)中的t</span>
<span class="pl-s">    :return:对应式(50)中的x_{t - 1}</span>
<span class="pl-s">    """</span>
    <span class="pl-c">#α_t = alphas[t - 1]</span>
    <span class="pl-s1">alpha</span> <span class="pl-c1">=</span> <span class="pl-s1">alphas</span>[<span class="pl-s1">timestep</span>]
    <span class="pl-c">#β_t = betas[t - 1]</span>
    <span class="pl-s1">beta</span> <span class="pl-c1">=</span> <span class="pl-s1">betas</span>[<span class="pl-s1">timestep</span>]
    <span class="pl-s1">alpha_bar</span> <span class="pl-c1">=</span> <span class="pl-s1">alphas_bar</span>[<span class="pl-s1">timestep_s</span>]
    <span class="pl-s1">alpha_bar_pre</span> <span class="pl-c1">=</span> <span class="pl-s1">alphas_bar</span>[<span class="pl-s1">timestep</span>]
    <span class="pl-c">#x_t前的系数</span>
    <span class="pl-s1">cof1</span> <span class="pl-c1">=</span> <span class="pl-c1">1</span> <span class="pl-c1">/</span> <span class="pl-s1">alpha</span>.<span class="pl-c1">sqrt</span>()
    <span class="pl-c">#预测噪声前的系数</span>
    <span class="pl-s1">cof2</span> <span class="pl-c1">=</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha</span>) <span class="pl-c1">/</span> (<span class="pl-s1">alpha</span> <span class="pl-c1">*</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar</span>)).<span class="pl-c1">sqrt</span>()
    <span class="pl-c">#随机噪声前的系数</span>
    <span class="pl-s1">var</span> <span class="pl-c1">=</span> ((<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar_pre</span>) <span class="pl-c1">/</span> (<span class="pl-c1">1</span> <span class="pl-c1">-</span> <span class="pl-s1">alpha_bar</span>) <span class="pl-c1">*</span> <span class="pl-s1">beta</span>).<span class="pl-c1">sqrt</span>()
    <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">var</span> <span class="pl-c1">*</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span><span class="pl-s1">xs</span>.<span class="pl-c1">shape</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#t的形状为[1]，将其形状展开为[batch_size]以放入模型中进行计算</span>
    <span class="pl-s1">timestep_s</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">full</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span>[<span class="pl-s1">xs</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">0</span>]], <span class="pl-s1">dtype</span><span class="pl-c1">=</span><span class="pl-s1">torch</span>.<span class="pl-c1">long</span>, <span class="pl-s1">fill_value</span><span class="pl-c1">=</span><span class="pl-s1">timestep_s</span>).<span class="pl-c1">cuda</span>()
    <span class="pl-c">#式(50)</span>
    <span class="pl-k">return</span> <span class="pl-s1">cof1</span> <span class="pl-c1">*</span> <span class="pl-s1">xs</span> <span class="pl-c1">-</span> <span class="pl-s1">cof2</span> <span class="pl-c1">*</span> <span class="pl-en">model</span>(<span class="pl-s1">xs</span>, <span class="pl-s1">timestep_s</span>) <span class="pl-c1">+</span> <span class="pl-s1">noise</span></pre></div>
<p>采样的核心方法：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">trailing</span>(<span class="pl-s1">steps</span>):
    <span class="pl-k">return</span> <span class="pl-s1">torch</span>.<span class="pl-c1">arange</span>(<span class="pl-s1">time_steps</span>, <span class="pl-c1">0</span>, <span class="pl-c1">-</span><span class="pl-s1">time_steps</span> <span class="pl-c1">/</span> <span class="pl-s1">steps</span>).<span class="pl-c1">flip</span>(<span class="pl-c1">0</span>).<span class="pl-c1">round</span>().<span class="pl-c1">int</span>().<span class="pl-c1">cuda</span>()


<span class="pl-k">def</span> <span class="pl-en">sample</span>(<span class="pl-s1">formats</span>, <span class="pl-s1">configs</span>, <span class="pl-s1">batch</span><span class="pl-c1">=</span><span class="pl-c1">1</span>, <span class="pl-s1">noise</span><span class="pl-c1">=</span><span class="pl-c1">None</span>, <span class="pl-s1">steps</span><span class="pl-c1">=</span><span class="pl-c1">1000</span>,
           <span class="pl-s1">solver</span><span class="pl-c1">=</span><span class="pl-s1">ddpm</span>, <span class="pl-s1">time_schedule</span><span class="pl-c1">=</span><span class="pl-s1">trailing</span>, <span class="pl-s1">desc</span><span class="pl-c1">=</span><span class="pl-s">''</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    :param formats:一系列保存格式，输入为方法，详见保存格式方法</span>
<span class="pl-s">    :param configs:保存的可修改配置，输入为词典。详见默认保存格式</span>
<span class="pl-s">    :param batch:一批次采样的图片数量</span>
<span class="pl-s">    :param noise:初始的噪声，如果为None，会生成随机噪声</span>
<span class="pl-s">    :param steps:采样步数，以目前的进度而言，该值只能等于1000，快速采样将在以后的文章中介绍</span>
<span class="pl-s">    :param solver:采样器，以目前的进度而言，该值只能等于ddpm，其他采样器将在以后的文章中介绍</span>
<span class="pl-s">    :param time_schedule:采样时间序列，使用默认的trailing</span>
<span class="pl-s">    :param desc:可在tqdm进度条中显示额外的注释说明</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">randn</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span>(<span class="pl-s1">batch</span>, <span class="pl-s1">channels</span>, <span class="pl-s1">image_size</span>, <span class="pl-s1">image_size</span>)).<span class="pl-c1">cuda</span>() \
        <span class="pl-k">if</span> <span class="pl-s1">noise</span> <span class="pl-c1">is</span> <span class="pl-c1">None</span> <span class="pl-k">else</span> <span class="pl-s1">noise</span>
    <span class="pl-s1">img_list</span> <span class="pl-c1">=</span> <span class="pl-en">sample_loop</span>(<span class="pl-s1">noise</span>, <span class="pl-s1">steps</span>, <span class="pl-s1">solver</span>, <span class="pl-s1">time_schedule</span>, <span class="pl-s1">desc</span>)
    <span class="pl-k">for</span> <span class="pl-s1">i</span>, <span class="pl-s1">format_</span> <span class="pl-c1">in</span> <span class="pl-en">enumerate</span>(<span class="pl-s1">formats</span>):
        <span class="pl-en">format_</span>(<span class="pl-s1">img_list</span>, {} <span class="pl-k">if</span> <span class="pl-en">len</span>(<span class="pl-s1">configs</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span> <span class="pl-c1">&lt;</span> <span class="pl-s1">i</span> <span class="pl-c1">or</span> <span class="pl-s1">configs</span>[<span class="pl-s1">i</span>] <span class="pl-c1">is</span> <span class="pl-c1">None</span> <span class="pl-k">else</span> <span class="pl-s1">configs</span>[<span class="pl-s1">i</span>])


<span class="pl-k">def</span> <span class="pl-en">sample_loop</span>(<span class="pl-s1">noise</span>, <span class="pl-s1">steps</span>, <span class="pl-s1">solver</span>, <span class="pl-s1">time_schedule</span>, <span class="pl-s1">extra_desc</span><span class="pl-c1">=</span><span class="pl-s">''</span>):
    <span class="pl-c">#首先会创建一个列表，其中包含了初始噪声</span>
    <span class="pl-s1">result</span> <span class="pl-c1">=</span> [<span class="pl-s1">noise</span>.<span class="pl-c1">detach</span>().<span class="pl-c1">cpu</span>()]
    <span class="pl-c">#获取采样时间戳，以目前的进度而言，该时间戳为[1, 2, ……, 1000]</span>
    <span class="pl-s1">times_s</span> <span class="pl-c1">=</span> <span class="pl-en">time_schedule</span>(<span class="pl-s1">steps</span>)
    <span class="pl-c">#获取偏移的时间戳，该时间戳为[0, 1, ……, 999]</span>
    <span class="pl-s1">times_t</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">cat</span>((<span class="pl-s1">torch</span>.<span class="pl-c1">tensor</span>((<span class="pl-c1">0</span>,)).<span class="pl-c1">cuda</span>(), <span class="pl-s1">times_s</span>[:<span class="pl-c1">-</span><span class="pl-c1">1</span>]))
    <span class="pl-c">#进行迭代采样</span>
    <span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">tqdm</span>(
            <span class="pl-en">reversed</span>(<span class="pl-en">range</span>(<span class="pl-s1">steps</span>)),
            <span class="pl-s1">desc</span><span class="pl-c1">=</span><span class="pl-s">'Now Sampling...'</span> <span class="pl-c1">+</span> <span class="pl-s1">extra_desc</span>,
            <span class="pl-s1">total</span><span class="pl-c1">=</span><span class="pl-s1">steps</span>
    ):
        <span class="pl-c">#使用求解器进行单次迭代</span>
        <span class="pl-s1">noise</span> <span class="pl-c1">=</span> <span class="pl-en">solver</span>(<span class="pl-s1">noise</span>, <span class="pl-s1">times_t</span>[<span class="pl-s1">i</span>], <span class="pl-s1">times_s</span>[<span class="pl-s1">i</span>])
        <span class="pl-c">#将中间状态保存到列表中</span>
        <span class="pl-s1">result</span>.<span class="pl-c1">append</span>(<span class="pl-s1">noise</span>.<span class="pl-c1">detach</span>().<span class="pl-c1">cpu</span>())
    <span class="pl-c">#返回带有整个中间状态的列表</span>
    <span class="pl-k">return</span> <span class="pl-s1">result</span></pre></div>
<p>对于采样获得的从$t = 1000$到$t = 0$时刻全部状态，定义一个以网格形式保存采样结果的方法：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-s">"""</span>
<span class="pl-s">format为grid时可使用的全部配置</span>
<span class="pl-s">saving_folder  :保存的文件夹</span>
<span class="pl-s">name           :保存的文件名</span>
<span class="pl-s">reverse        :是否翻转网格长和宽</span>
<span class="pl-s">padding_pixels :图片与图片之间的间隔</span>
<span class="pl-s">"""</span>
<span class="pl-s1">grid_config</span> <span class="pl-c1">=</span> {
    <span class="pl-s">'saving_folder'</span>: <span class="pl-s">'.'</span>,
    <span class="pl-s">'name'</span>: <span class="pl-s">'_grid'</span>,
    <span class="pl-s">'reverse'</span>: <span class="pl-c1">False</span>,
    <span class="pl-s">'padding_pixels'</span>: <span class="pl-c1">2</span>,
}


<span class="pl-k">def</span> <span class="pl-en">grid</span>(<span class="pl-s1">img_list</span>, <span class="pl-s1">config</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    用于保存的format方法变量</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">torchvision</span>.<span class="pl-c1">io</span>.<span class="pl-c1">write_png</span>(
        <span class="pl-en">to_grid</span>(<span class="pl-en">to_rgb</span>(<span class="pl-s1">img_list</span>[<span class="pl-c1">-</span><span class="pl-c1">1</span>]), <span class="pl-s1">config</span>),
        <span class="pl-en">get</span>(<span class="pl-s">'saving_folder'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>) <span class="pl-c1">+</span> <span class="pl-s">'/'</span> <span class="pl-c1">+</span> <span class="pl-en">get</span>(<span class="pl-s">'name'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>) <span class="pl-c1">+</span> <span class="pl-s">'.png'</span>
    )


<span class="pl-k">def</span> <span class="pl-en">to_rgb</span>(<span class="pl-s1">tensor</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    将张量变为图片格式</span>
<span class="pl-s">    """</span>
    <span class="pl-k">return</span> ((<span class="pl-s1">tensor</span> <span class="pl-c1">+</span> <span class="pl-s1">torch</span>.<span class="pl-c1">ones_like</span>(<span class="pl-s1">tensor</span>)) <span class="pl-c1">/</span> <span class="pl-c1">2</span> <span class="pl-c1">*</span> <span class="pl-c1">255</span>).<span class="pl-c1">clip</span>(<span class="pl-c1">0</span>, <span class="pl-c1">255</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>)


<span class="pl-k">def</span> <span class="pl-en">closest_divisors</span>(<span class="pl-s1">num</span>: <span class="pl-smi">int</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    用于计算长和宽，使长和宽尽可能接近</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">a</span>, <span class="pl-s1">b</span>, <span class="pl-s1">i</span> <span class="pl-c1">=</span> <span class="pl-c1">1</span>, <span class="pl-s1">num</span>, <span class="pl-c1">0</span>
    <span class="pl-k">while</span> <span class="pl-s1">a</span> <span class="pl-c1">&lt;</span> <span class="pl-s1">b</span>:
        <span class="pl-s1">i</span> <span class="pl-c1">+=</span> <span class="pl-c1">1</span>
        <span class="pl-k">if</span> <span class="pl-s1">num</span> <span class="pl-c1">%</span> <span class="pl-s1">i</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
            <span class="pl-s1">a</span> <span class="pl-c1">=</span> <span class="pl-s1">i</span>
            <span class="pl-s1">b</span> <span class="pl-c1">=</span> <span class="pl-s1">num</span> <span class="pl-c1">//</span> <span class="pl-s1">a</span>
    <span class="pl-k">return</span> [<span class="pl-s1">b</span>, <span class="pl-s1">a</span>]


<span class="pl-k">def</span> <span class="pl-en">to_pixel_coord</span>(<span class="pl-s1">num</span>, <span class="pl-s1">padding_pixels</span>: <span class="pl-smi">int</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    用于计算像素点坐标，以制作网格</span>
<span class="pl-s">    """</span>
    <span class="pl-k">return</span> <span class="pl-s1">num</span> <span class="pl-c1">*</span> <span class="pl-s1">image_size</span> <span class="pl-c1">+</span> (<span class="pl-s1">num</span> <span class="pl-c1">+</span> <span class="pl-c1">1</span>) <span class="pl-c1">*</span> <span class="pl-s1">padding_pixels</span>


<span class="pl-k">def</span> <span class="pl-en">to_grid</span>(<span class="pl-s1">imgs</span>, <span class="pl-s1">config</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    将一批图片张量转化为单个的网格张量形式</span>
<span class="pl-s">    """</span>
    <span class="pl-s1">batch</span> <span class="pl-c1">=</span> <span class="pl-s1">imgs</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">0</span>]
    <span class="pl-s1">x</span>, <span class="pl-s1">y</span> <span class="pl-c1">=</span> <span class="pl-en">closest_divisors</span>(<span class="pl-s1">batch</span>)
    <span class="pl-k">if</span> <span class="pl-en">get</span>(<span class="pl-s">'reverse'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>):
        <span class="pl-s1">x</span>, <span class="pl-s1">y</span> <span class="pl-c1">=</span> <span class="pl-s1">y</span>, <span class="pl-s1">x</span>
    <span class="pl-s1">px</span> <span class="pl-c1">=</span> <span class="pl-en">get</span>(<span class="pl-s">'padding_pixels'</span>, <span class="pl-s1">config</span>, <span class="pl-s1">grid_config</span>)
    <span class="pl-s1">width</span> <span class="pl-c1">=</span> <span class="pl-en">to_pixel_coord</span>(<span class="pl-s1">x</span>, <span class="pl-s1">px</span>)
    <span class="pl-s1">height</span> <span class="pl-c1">=</span> <span class="pl-en">to_pixel_coord</span>(<span class="pl-s1">y</span>, <span class="pl-s1">px</span>)
    <span class="pl-s1">result</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-c1">full</span>(<span class="pl-s1">size</span><span class="pl-c1">=</span>(<span class="pl-s1">imgs</span>.<span class="pl-c1">shape</span>[<span class="pl-c1">1</span>], <span class="pl-s1">height</span>, <span class="pl-s1">width</span>), <span class="pl-s1">fill_value</span><span class="pl-c1">=</span><span class="pl-c1">1.</span>).<span class="pl-c1">to</span>(<span class="pl-s1">torch</span>.<span class="pl-c1">uint8</span>)
    <span class="pl-k">for</span> <span class="pl-s1">j</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">batch</span>):
        <span class="pl-s1">h_coord</span> <span class="pl-c1">=</span> <span class="pl-s1">j</span> <span class="pl-c1">//</span> <span class="pl-s1">x</span> <span class="pl-c1">*</span> (<span class="pl-s1">image_size</span> <span class="pl-c1">+</span> <span class="pl-s1">px</span>) <span class="pl-c1">+</span> <span class="pl-s1">px</span>
        <span class="pl-s1">w_coord</span> <span class="pl-c1">=</span> <span class="pl-s1">j</span> <span class="pl-c1">%</span> <span class="pl-s1">x</span> <span class="pl-c1">*</span> (<span class="pl-s1">image_size</span> <span class="pl-c1">+</span> <span class="pl-s1">px</span>) <span class="pl-c1">+</span> <span class="pl-s1">px</span>
        <span class="pl-s1">result</span>[:, <span class="pl-s1">h_coord</span>:<span class="pl-s1">h_coord</span> <span class="pl-c1">+</span> <span class="pl-s1">image_size</span>, <span class="pl-s1">w_coord</span>: <span class="pl-s1">w_coord</span> <span class="pl-c1">+</span> <span class="pl-s1">image_size</span>] <span class="pl-c1">=</span> <span class="pl-s1">imgs</span>[<span class="pl-s1">j</span>]
    <span class="pl-k">return</span> <span class="pl-s1">result</span>


<span class="pl-k">def</span> <span class="pl-en">get</span>(<span class="pl-s1">par</span>, <span class="pl-s1">config</span>, <span class="pl-s1">config_</span>):
    <span class="pl-s">"""</span>
<span class="pl-s">    获取可配置的参数值</span>
<span class="pl-s">    """</span>
    <span class="pl-k">try</span>:
        <span class="pl-k">return</span> <span class="pl-s1">config</span>[<span class="pl-s1">par</span>]
    <span class="pl-k">except</span>:
        <span class="pl-k">return</span> <span class="pl-s1">config_</span>[<span class="pl-s1">par</span>]</pre></div>
<p>进而，便可完成训练过程中所提到的milestone_sample方法：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">def</span> <span class="pl-en">milestone_sample</span>(<span class="pl-s1">global_epoch</span>, <span class="pl-s1">solver</span><span class="pl-c1">=</span><span class="pl-s1">ddpm</span>):
    <span class="pl-s1">milestone_path</span> <span class="pl-c1">=</span> <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/milestone"</span>
    <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">os</span>.<span class="pl-c1">path</span>.<span class="pl-c1">exists</span>(<span class="pl-s1">milestone_path</span>):
        <span class="pl-s1">os</span>.<span class="pl-c1">mkdir</span>(<span class="pl-s1">milestone_path</span>)
    <span class="pl-en">print</span>(<span class="pl-s">"Now Sampling Milestone"</span>)
    <span class="pl-s1">time</span>.<span class="pl-c1">sleep</span>(<span class="pl-c1">0.1</span>)
    <span class="pl-c">#调用采样核心方法，使用grid作为保存格式，将结果保存到milestone文件夹，一次采样16张图片</span>
    <span class="pl-en">sample</span>(
        <span class="pl-s1">formats</span><span class="pl-c1">=</span>[<span class="pl-s1">grid</span>],
        <span class="pl-s1">configs</span><span class="pl-c1">=</span>[{
            <span class="pl-s">'saving_folder'</span>: <span class="pl-s1">checkpoint_folder</span> <span class="pl-c1">+</span> <span class="pl-s">"/milestone"</span>,
            <span class="pl-s">'name'</span>: <span class="pl-s">'epoch_%d'</span> <span class="pl-c1">%</span> <span class="pl-s1">global_epoch</span>
        }],
        <span class="pl-s1">batch</span><span class="pl-c1">=</span><span class="pl-c1">16</span>,
        <span class="pl-s1">solver</span><span class="pl-c1">=</span><span class="pl-s1">solver</span>
    )
    <span class="pl-en">print</span>(<span class="pl-s">"----------------------------------------------------------------"</span>)</pre></div>
<h2>代码运行</h2>
<p>这样一来，便完成了DDPM的代码实现，即可进行训练：</p>
<div class="highlight highlight-source-python"><pre class="notranslate"><span class="pl-k">if</span> <span class="pl-s1">__name__</span> <span class="pl-c1">==</span> <span class="pl-s">'__main__'</span>:
    <span class="pl-en">train</span>()</pre></div>
<p>训练的前100次迭代过程：</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/cifar1_10_100.png"/></p></p>
<p>训练的500次迭代过程：</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/cifar1_50_500.png"/></p></p>
<p>训练的损失值变化：</p>
<p><p align="center"><img srcset="https://OmnisyR.github.io/figs/cifar1_loss.png" width="400" height="300"/></p></p>
<h2>总结</h2>
<p>至此，便完成了DDPM算法上的复现，若是亲自运行代码了，必然会感受到扩散模型对算力的需求之大，也才激发了人们后续关于快速采样的研究。</p>
<p>由于<code class="notranslate">博客框架的限制</code>，还有很多内容没有能够讲明白，一些理解较为困难的地方后续我也会尽量补充解释，或是另开一篇文章进行讲解。;;;c</p></div>
<div style="font-size:small;margin-top:8px;float:right;">转载文章请注明出处</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://OmnisyR.github.io">OmnisyR's Blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("07/23/2025"!=""){
    var startSite=new Date("07/23/2025");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek main https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.disabled=true;
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","OmnisyR/OmnisyR.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>
<script src='https://OmnisyR.github.io/assets/HyperTOC.js'></script><script>MathJax = {tex: {inlineMath: [["$", "$"]]}};</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</html>
